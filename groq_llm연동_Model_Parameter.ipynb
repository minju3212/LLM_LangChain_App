{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d02dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9284112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Before (논리적이고 보수적인 이야기)\n",
      "어느 날, 마법의 세계에서 벌어진 예상치 못한 사건이 있었습니다. 마법사들은 마법의 숲에서 마법의 꽃을 발견했습니다. 이 꽃은 마법의 세계에서 가장 강력한 마법의 힘을 가지고 있었습니다.\n",
      "\n",
      "마법사들은 이 꽃을 얻기 위해 경쟁을 벌였습니다. 하지만, 이 꽃은 예상치 못한 방식으로 반응했습니다. 이 꽃은 마법사들에게 마법의 힘을 빼앗아 버렸습니다.\n",
      "\n",
      "마법사들은 자신들의 마법의 힘이 사라진 것을 발견하고 충격을 받았습니다. 그들은 이 꽃을 어떻게 해야 할지 몰랐습니다. 그들은 이 꽃을 파괴하려고 했지만, 이 꽃은 파괴되지 않았습니다.\n",
      "\n",
      "이 꽃은\n",
      "\n",
      "-------------------------\n",
      "\n",
      " After (창의적인 이야기, 더 풍부한 표현)\n",
      "마법사 엘리아는 조용한 밤에 자신만의 작은 마법 실험실을 운영하고 있었습니다. 그녀는 별빛이 가득한 밤하늘을 바라보며 새로운 마법 주문을 연구하고 있었습니다. 그런데, 갑자기 실험실 문이 열리며 나타난 것은 엘리아가 전혀 예상하지 못한 존재였습니다. 그것은 작은 용이었습니다.\n",
      "\n",
      "작은 용은 엘리아의 실험실에 들어가자마자 자신의 몸을 바꾸기 시작했습니다. 그리고 그 작은 용은 엘리아의 눈앞에서 순식간에 엘리아와 똑같이 생긴 모습으로 변했습니다. 엘리아는 깜짝 놀랐지만, 작은 용이 자신의 모습을 흉내 내고 있는 것을 보고 궁금증을 느꼈습니다.\n",
      "\n",
      "엘리아는 작은 용에게 마법을 사용하여 자신의 모습을 흉내 내는 이유를 물었습니다. 작은 용은 엘리아에게 마법사들의 마법으로 인해 마법사들의 영혼이 용의 모습으로 바뀌고 있다고 설명했습니다. 엘리아는 작은 용이 자신의 영혼을 대신하여 마법사로서의 삶을 살아왔음을 알게 되었습니다.\n",
      "\n",
      "엘리아는 작은 용이 자신의 영혼을 대신하여 살아온 시간 동안의 경험을 듣고 싶었습니다. 작은 용은 엘리아에게 자신이 살아온 시간 동안의 이야기를 들려주었습니다. 작은 용은 엘리아가 마법사로서의 삶을 살면서 겪었던 어려움과 성공을 대신하여 살아왔고, 엘리아의 마법사로서\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#  보수적인 설정 (일관된, 논리적인 이야기)\n",
    "llm_before = ChatOpenAI(\n",
    "    #model=\"gpt-3.5-turbo-0125\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.2,  # 낮은 온도로 예측 가능한 출력\n",
    "    presence_penalty=0.0,  # 기존 패턴 유지\n",
    "    frequency_penalty=0.0,  # 반복 허용\n",
    "    max_tokens=150,  # 출력 길이 제한\n",
    "    top_p=1.0  # 확률 상위 100% 내에서 선택 (제한 없음)\n",
    ")\n",
    "\n",
    "#  창의적인 설정 (더 독창적이고 예측 불가능한 이야기)\n",
    "llm_after = ChatOpenAI(\n",
    "    #model=\"gpt-3.5-turbo-0125\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=1.2,  # 높은 온도로 창의적인 답변 유도\n",
    "    presence_penalty=1.2,  # 새로운 단어와 개념 유도\n",
    "    frequency_penalty=0.5,  # 반복을 억제하여 더 다양한 표현 생성\n",
    "    max_tokens=300,  # 더 긴 이야기 허용\n",
    "    top_p=0.8  # 제한 없이 다양한 단어 선택 가능\n",
    ")\n",
    "\n",
    "# 질문 설정: 짧은 판타지 이야기 생성\n",
    "# question = \"마법의 세계에서 용이 인간과 친구가 되는 짧은 이야기를 써 주세요.\"\n",
    "question = \"마법의 세계에서 벌어지는 예상치 못한 사건을 주제로 독창적인 짧은 이야기를 만들어 주세요.\"\n",
    "\n",
    "# 모델 호출\n",
    "response_before = llm_before.invoke(question)\n",
    "response_after = llm_after.invoke(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(\" Before (논리적이고 보수적인 이야기)\")\n",
    "print(response_before.content)\n",
    "\n",
    "print(\"\\n-------------------------\\n\")\n",
    "\n",
    "print(\" After (창의적인 이야기, 더 풍부한 표현)\")\n",
    "print(response_after.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc82d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Before] 모델 결과\n",
      "서울과 경기도 일대를 여행하는 3박4일 추천 일정입니다.\n",
      "\n",
      "1일차: 서울\n",
      "\n",
      "*   오전: 서울에 도착하여 호텔에 체크인하고 간단한 아침을 먹는다.\n",
      "*   10:00: 서울의 상징인 N서울타워에 방문하여 서울의 전경을 감상한다. \n",
      "*   13:00: 점심은 광화문 근처에서 먹는다. \n",
      "*   14:00: 경복궁에 방문하여 한국의 전통 문화를 체험한다. \n",
      "*   17:00: 덕수궁으로 이동하여 대한제국의 역사를 배운다. \n",
      "*   저녁: 서울의 맛있는 저녁을 먹는다.\n",
      "\n",
      "2일차: 경기도 수원\n",
      "\n",
      "*   오전: 수원으로 이동하여 수원화성을 방문한다. \n",
      "*   12:00: 수원화성 근처에서 점심을 먹는다. \n",
      "*   14:00: 수원시립미술관에 방문하여 현대 미술을 감상한다. \n",
      "*   17:00: 수원의 야경을 감상한다. \n",
      "*   저녁: 수원의 맛있는 저녁을 먹는다.\n",
      "\n",
      "3일차: 경기도 파주\n",
      "\n",
      "*   오전: 파주로 이동하여 헤이리 예술마을을 방문한다. \n",
      "*   13:00: 헤이리 예술마을 근처에서 점심을 먹는다. \n",
      "*   14:00: 임진각에 방문하여 한국전쟁의 역\n",
      "\n",
      "================================================================================\n",
      "\n",
      " [After] 모델 결과\n",
      "가족과 함께 3박 4일 동안 한국에서 여유롭게 여행할 수 있는 일정을 동선을 고려하여 추천해 드리겠습니다.\n",
      "\n",
      "### **일정: 3박 4일**\n",
      "\n",
      "### **여행지: 서울 및 경기도**\n",
      "\n",
      "### **일정:**\n",
      "\n",
      "**1일차: 서울**\n",
      "\n",
      "*   오전: 서울에 도착하여 호텔에 체크인합니다. \n",
      "*   오후: 서울의 대표적인 관광지인 **경복궁**을 방문합니다. 경복궁은 한국 역사의 상징적인 장소로, 가족과 함께 역사와 문화를 체험할 수 있는 좋은 장소입니다. \n",
      "*   저녁: **광화문** 일대의 맛집에서 저녁 식사를 합니다.\n",
      "\n",
      "**2일차: 서울**\n",
      "\n",
      "*   오전: **북촌 한옥마을**을 방문합니다. 북촌 한옥마을은 전통적인 한국 건축 양식을 볼 수 있는 곳으로, 가족과 함께 한국의 전통 문화를 체험할 수 있습니다. \n",
      "*   오후: **롯데월드**를 방문합니다. 롯데월드는 다양한 놀이기구와 테마파크를 제공하여 가족과 함께 즐거운 시간을 보낼 수 있습니다. \n",
      "*   저녁: **홍대** 일대의 맛집에서 저녁 식사를 합니다.\n",
      "\n",
      "**3일차: 경기도**\n",
      "\n",
      "*   오전: **수원**에 있는 **화성**을 방문합니다. 화성은 한국의 역사적인 장소로, 가족과 함께 역사와 문화를 체험할 수 있는 좋은 장소입니다. \n",
      "*   오후: **수원**의 **수원화성** 일대를 산책합니다. 수원화성은 한국의 역사적인 장소로, 가족과 함께 역사와 문화를 체험할 수 있습니다. \n",
      "*   저녁: **수원**의 맛집에서 저녁 식사를 합니다.\n",
      "\n",
      "**4일차: 서울**\n",
      "\n",
      "*   오전: **서울랜드**를 방문합니다. 서울랜드는 다양한 놀이기구와 테마파크를 제공하여 가족과 함께 즐거운 시간을 보낼 수 있습니다. \n",
      "*   오후: **서울**의 **동대문 디자인 플라자**를 방문합니다. 동대문 디자인 플라자는 한국의 패션과 디자인을 체험할 수 있는 곳으로, 가족과 함께 한국의 현대 문화를 체험할 수 있습니다. \n",
      "*   저녁: **서울**의 맛집에서 저녁 식사를 합니다.\n",
      "\n",
      "### **교통:**\n",
      "\n",
      "*   서울과 경기도는 대중교통이 잘 발달되어 있으므로, 지하철과 버스를 이용하여 이동할 수 있습니다.\n",
      "\n",
      "### **숙박:**\n",
      "\n",
      "*   서울과 경기도에는 다양한 숙박 옵션이 있으므로, 가족의 예산과 선호도에 따라 호텔이나 게스트하우스를 선택할 수 있습니다.\n",
      "\n",
      "### **예산:**\n",
      "\n",
      "*   3박 4일 동안의 여행 예산은 가족의 규모와 선호도에 따라 다르겠지만, 다음과 같은 예산을 고려할 수 있습니다.\n",
      "*   숙박: 50만 원 - 100만 원\n",
      "*   교통: 10만 원 - 20만 원\n",
      "*   식사: 30만 원 - 50만 원\n",
      "*   관광: 20만 원 - 30만 원\n",
      "\n",
      "### **총 예산: 110만 원 - 200만 원**\n",
      "\n",
      "이 일정은 가족과 함께 여유롭게 여행할 수 있는 최적의 일정입니다. 서울과 경기도의 다양한 관광지와 문화를 체험할 수 있으며, 교통과 숙박도 편리합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "#  모델 파라미터 (Before: 기본적인 추천 / After: 맞춤형 세부 정보 추가)\n",
    "before_params = {\n",
    "    \"temperature\": 0.7,         # 랜덤성을 적절히 유지 (다양한 답변 유도)\n",
    "    \"max_tokens\": 300,          # 응답 길이를 적절히 조절\n",
    "    \"frequency_penalty\": 0.5,   # 반복 단어 억제\n",
    "    \"presence_penalty\": 0.5,    # 새로운 단어 포함 장려\n",
    "}\n",
    "\n",
    "after_params = {\n",
    "    \"temperature\": 0.3,         # 창의성을 낮추고 정확한 답변 유도\n",
    "    \"max_tokens\": 800,          # 더 긴 답변을 생성 (세부 정보 포함)\n",
    "    \"top_p\": 0.85,              # 확률 기반 샘플링 (일관성과 다양성 균형)\n",
    "    \"frequency_penalty\": 0.2,   # 반복 단어 감소 (자연스러운 답변)\n",
    "    \"presence_penalty\": 0.3,    # 새로운 정보 포함 장려\n",
    "}\n",
    "\n",
    "#  두 개의 모델 생성 (Before / After)\n",
    "#before_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **before_params)\n",
    "before_model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    **before_params\n",
    ")\n",
    "#after_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **after_params)\n",
    "after_model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    **after_params\n",
    ")\n",
    "\n",
    "#  프롬프트 구성 (올바른 ChatMessagePromptTemplate 사용)\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"당신은 여행 전문가입니다. 사용자의 요청에 맞는 최적의 여행지를 추천해 주세요.\"\n",
    ")\n",
    "\n",
    "user_message = HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message, user_message])\n",
    "\n",
    "#  체인 생성 (Before / After)\n",
    "before_chain = chat_prompt | before_model\n",
    "after_chain = chat_prompt | after_model\n",
    "\n",
    "#  질문 설정 (Before / After의 차이점을 비교할 수 있도록 변경)\n",
    "test_question = \"가족과 함께 3박 4일 동안 한국에서 여유롭게 여행할 수 있는 일정을 동선을 고려하여 자세하게 추천해 주세요.\"\n",
    "\n",
    "#  Before 모델 실행\n",
    "before_response = before_chain.invoke({\"user_input\": test_question})\n",
    "\n",
    "#  After 모델 실행\n",
    "after_response = after_chain.invoke({\"user_input\": test_question})\n",
    "\n",
    "#  결과 출력\n",
    "print(\" [Before] 모델 결과\")\n",
    "print(before_response.content)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")  # 가독성을 위한 구분선\n",
    "print(\" [After] 모델 결과\")\n",
    "print(after_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d372b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Before] 기본 max_tokens=150 (기본 답변)\n",
      "과학 기술의 발전으로 미래에 시간 여행이 가능해진다고 가정했을 때, 저는 기원후 500년 전후로 가고 싶습니다. 고대 로마 제국은 당시의 모든 과학, 예술, 철학의 정수를 흡수한 문화의 보고이면서, 현대까지도 많은 영향을 미치는 문화적 유산을 남긴 문명입니다. 로마 제국 시기에는 철도로 만들어진 인프라, 우편 제도의 도입 등 후대까지 전해지는 놀라운 업적들을 남겼습니다. 또한 다양한 예술과 철학, 건축 양식 등이 탄생한 시기기도 합니다. 저는 로마 제국 시기에 가서 그 시대의 생활상을 보고 싶습니다.\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      " [After] max_tokens=150, stop=['.'] (첫 번째 마침표에서 응답 중단)\n",
      "### **고대 이집트 탐방**\n",
      "\n",
      "만약 시간여행이 가능하다면, 저는 고대 이집트의 풍광이 절정에 달했던 기원전 2550년으로 돌아가고 싶습니다\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      " [After] max_tokens=150, temperature=0.8 (창의적인 답변)\n",
      "시간 여행이 가능하다면, 저는 르네상스 시대의 이탈리아로 가고 싶습니다. 특히, 15세기 후반의 플로렌스를 방문하고 싶어요.\n",
      "\n",
      "르네상스 시대는 예술, 과학, 철학이 꽃피던 시기였고, 그 중심에는 이탈리아가 있었습니다. 플로렌스는 이 시대의 문화적, 예술적 중심지였으며, 레온나르도 다 빈치, 미켈란젤로, 갈릴레오 갈릴레이와 같은 위대한 인물들이 활동하던 곳입니다.\n",
      "\n",
      "저는 르네상스 시대의 이탈리아로 가서 예술가들과 철학자들이 서로 교류하고 아이디어를 나누는 모습을 보고 싶습니다. 또한, 레\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "#  프롬프트 설정 (천문학 질문에 대한 답변을 생성하는 시스템)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"이 시스템은 천문학 질문에 대해 명확하고 자세한 답변을 제공할 수 있습니다.\"),\n",
    "    (\"user\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "#  기본 모델 설정 (기본적인 답변 생성)\n",
    "#base_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", max_tokens=150)  # 150 토큰 제한\n",
    "base_model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "#  질문 설정\n",
    "# 1. MAX_TOKENS 차이를 보여주는 질문 (길이 제한 효과)\n",
    "max_tokens_question = \"인공지능의 발전이 미래 사회에 미칠 영향을 긍정적 측면과 부정적 측면으로 나누어 자세히 설명해 주세요.\"\n",
    "\n",
    "# 2. STOP 파라미터 차이를 보여주는 질문 (중단점 효과)\n",
    "stop_question = \"Python 프로그래밍을 배우는 초보자에게 추천하는 학습 단계를 순서대로 설명해 주세요. 각 단계별로 구체적인 방법과 팁을 포함해서 답변해 주세요.\"\n",
    "\n",
    "# 3. TEMPERATURE 차이를 보여주는 질문 (창의성 vs 정확성)\n",
    "temperature_question = \"시간 여행이 가능하다면 과거의 어느 시대로 가고 싶은지와 그 이유를 창의적으로 설명해 주세요.\"\n",
    "\n",
    "# 4. 복합적 비교를 위한 질문 (모든 파라미터 효과)\n",
    "complex_question = \"화성에 인류가 정착하기 위해 필요한 기술과 준비사항들을 단계별로 설명하고, 각 단계에서 예상되는 도전과제와 해결방안을 제시해 주세요.\"\n",
    "\n",
    "\n",
    "question = temperature_question\n",
    "\n",
    "#  Before (기본 max_tokens=150)\n",
    "messages = prompt.format_messages(user_input=question)\n",
    "before_answer = base_model.invoke(messages)\n",
    "\n",
    "#  Before 출력\n",
    "print(\"\\n [Before] 기본 max_tokens=150 (기본 답변)\")\n",
    "print(before_answer.content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")  # 가독성을 위한 구분선\n",
    "\n",
    "#  After (파라미터 조정 후 비교)\n",
    "stop_chain = prompt | base_model.bind(max_tokens=150, stop=[\".\"])  # 첫 번째 마침표에서 중단\n",
    "temp_chain = prompt | base_model.bind(max_tokens=150, temperature=0.8)  # 창의적인 답변 유도\n",
    "\n",
    "stop_answer = stop_chain.invoke({\"user_input\": question})\n",
    "temp_answer = temp_chain.invoke({\"user_input\": question})\n",
    "\n",
    "#  After 출력 (stop vs temperature 비교)\n",
    "print(\" [After] max_tokens=150, stop=['.'] (첫 번째 마침표에서 응답 중단)\")\n",
    "print(stop_answer.content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")  # 가독성을 위한 구분선\n",
    "\n",
    "print(\" [After] max_tokens=150, temperature=0.8 (창의적인 답변)\")\n",
    "print(temp_answer.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
