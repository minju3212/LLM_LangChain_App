{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb12d960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain ChatGPT\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain ChatGPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20cee290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "#print(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5955a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"LangServe는 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db73f2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001B8D9238290> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001B8D92386B0> root_client=<openai.OpenAI object at 0x000001B8D91CE660> root_async_client=<openai.AsyncOpenAI object at 0x000001B8D9238590> model_name='gpt-4o-mini' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    #model=\"gpt-3.5-turbo-0125\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b635889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "<class 'str'>\n",
      "응답: LangServe는 주로 언어 모델과 관련된 서비스나 도구를 제공하는 플랫폼 또는 프레임워크를 지칭하는 이름으로 사용될 수 있습니다. 하지만 구체적인 정보나 공식적인 정의는 없기 때문에, 일반적으로 언어 모델을 서비스 형태로 제공하는 시스템의 특징에 대해 설명드리겠습니다.\n",
      "\n",
      "1. **언어 모델 API**: LangServe는 개발자들이 자연어 처리(NLP) 기능을 쉽게 통합할 수 있도록 API 형태로 제공될 수 있습니다. 이를 통해 텍스트 생성, 감정 분석, 번역 등의 기능을 사용할 수 있습니다.\n",
      "\n",
      "2. **모델 호스팅**: LangServe는 사용자들이 자신의 언어 모델을 호스팅하고 관리할 수 있는 환경을 제공할 수 있습니다. 이를 통해 사용자는 모델을 직접 훈련시키고, 배포할 수 있는 기능을 이용할 수 있습니다.\n",
      "\n",
      "3. **사용자 맞춤형**: 사용자 맞춤형 모델을 만들 수 있는 기능을 제공하는 경우도 많습니다. 사용자는 특정 데이터셋을 기반으로 모델을 fine-tuning하여 자신의 요구에 맞는 결과를 얻을 수 있습니다.\n",
      "\n",
      "4. **확장성**: LangServe는 여러 사용자가 동시에 접근할 수 있도록 설계되어 있어, 대규모 애플리케이션에서도 안정적으로 작동할 수 있습니다.\n",
      "\n",
      "5. **모니터링 및 분석**: 사용자는 API 사용량, 성능 및 기타 통계를 모니터링할 수 있는 도구를 제공받아, 서비스의 품질을 지속적으로 개선할 수 있습니다.\n",
      "\n",
      "6. **커뮤니티 및 지원**: 개발자들이 서로의 경험을 공유하고 도움을 받을 수 있는 커뮤니티 포럼이나 지원 채널을 제공할 수 있습니다.\n",
      "\n",
      "LangServe가 특정 플랫폼이나 제품이라면, 해당 플랫폼의 공식 문서를 참고하여 보다 구체적인 정보를 얻는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(type(response.content))\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
