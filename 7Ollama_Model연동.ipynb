{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "161c0025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama is running\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"http://127.0.0.1:11434\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f448c5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "('<think>\\n'\n",
      " '\\n'\n",
      " '</think>\\n'\n",
      " '\\n'\n",
      " 'LangChain is a high-level Python library for integrating language models '\n",
      " 'into applications, enabling developers to focus on their core tasks without '\n",
      " 'being overwhelmed by the low-level details of how to interact with them. It '\n",
      " 'provides abstractions for interacting with various model types (like '\n",
      " 'prompting, data fetching, and more), handling common interfaces (APIs and '\n",
      " 'clients), and managing complexity around API key management, logging, and '\n",
      " 'logging APIs. LangChain makes it easier to create custom applications that '\n",
      " 'can use any kind of language model without needing to understand the '\n",
      " 'intricacies of how they work under the hood.\\n'\n",
      " '\\n'\n",
      " 'Key features of LangChain include:\\n'\n",
      " '\\n'\n",
      " '1. **Model Management**: A simple way to switch between different model '\n",
      " 'types (like GPT-3, BERT, etc.) and use them within your application.\\n'\n",
      " '2. **Data Handling**: Simplifies interacting with external data sources '\n",
      " 'using an API client.\\n'\n",
      " '3. **Error Management**: Provides a unified API for error logging and '\n",
      " 'handling, making it easier to diagnose issues during development.\\n'\n",
      " '4. **Documentation and Tutorials**: LangChain includes documentation and '\n",
      " 'sample code for quick start guidance.\\n'\n",
      " '\\n'\n",
      " 'By abstracting away the complexities of working with language models, '\n",
      " 'LangChain allows developers to focus on building applications that leverage '\n",
      " 'these powerful tools. It is particularly useful in industries like chatbots, '\n",
      " 'customer service, content generation, and more where custom applications may '\n",
      " 'need to interact with external data sources or multiple model types.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pprint import pprint\n",
    "\n",
    "# Ollamaë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ llama3.2 ëª¨ë¸ ë¡œë“œ\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# ë” ì •í™•í•œ ì‘ë‹µì„ ìœ„í•œ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "# ìµœì‹  LangChain ë°©ì‹: RunnableSequence í™œìš©\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# ì‹¤í–‰ ì˜ˆì‹œ\n",
    "question = \"What is LangChain?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(type(response))\n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90636bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking \"íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€ìš”?\" which translates to \"What is Python?\" in English. I need to provide a detailed and accurate answer.\n",
      "\n",
      "First, I should start by defining Python as a programming language. Mention its creation, creator, and the year it was released. Then, highlight its key features like simplicity, readability, and versatility. It's important to note that Python is widely used in various fields such as web development, data analysis, artificial intelligence, and more.\n",
      "\n",
      "I should also include some basic information about its syntax, like how it uses indentation instead of braces, and the significance of the \"P\" in Python (for \"Python\" as in \"Programming Language\"). Maybe mention the community and resources available, like the official website and documentation.\n",
      "\n",
      "Additionally, it's good to touch on some popular libraries and frameworks that are part of Python, such as Django for web development, NumPy and pandas for data analysis, and TensorFlow or PyTorch for machine learning. Highlighting its popularity and the fact that it's open-source can add value.\n",
      "\n",
      "I need to make sure the answer is clear and not too technical, but still informative. Avoid jargon unless necessary, and explain terms like \"interpreted language\" and \"cross-platform\" if they're relevant. Also, mention that Python is used in both small scripts and large-scale applications.\n",
      "\n",
      "Check for any recent updates or changes in Python's features, but since the user is asking a general question, sticking to the basics is better. Maybe end with a positive note about its usefulness and the community support.\n",
      "</think>\n",
      "\n",
      "íŒŒì´ì¬ì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ, 1991ë…„ì— ê°„ë‹¨í•˜ê³  ì½ê¸° ì‰¬ìš´ ë¬¸ë²•ì„ íŠ¹ì§•ìœ¼ë¡œ í•œ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ì–¸ì–´ëŠ” ê°„ê²°í•œ ë¬¸ë²•ê³¼ ë†’ì€ ìƒì‚°ì„±ìœ¼ë¡œ ì¸í•´ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.  \n",
      "\n",
      "### ì£¼ìš” íŠ¹ì§•  \n",
      "1. **ê°„ê²°í•œ ë¬¸ë²•**: `if` ë¬¸ì— `else`ë¥¼ ë¶™ì´ê¸° ìœ„í•œ `if` ë¬¸ë²•ê³¼ `for` ë¬¸ì— `in`ì„ ë¶™ì´ê¸° ìœ„í•œ `for` ë¬¸ë²• ë“±ì´ ìˆì§€ë§Œ, ë“¤ì—¬ì“°ê¸°ë¡œ ë¬¸ì¥ì„ êµ¬ë¶„í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, ì½”ë“œì˜ ì½ê¸° ì‰¬ì›€ì„ ê°•ì¡°í•©ë‹ˆë‹¤.  \n",
      "2. **ë‹¤ì–‘í•œ í™œìš© ë¶„ì•¼**:  \n",
      "   - **ì›¹ ê°œë°œ**: Django, Flask ë“± ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©  \n",
      "   - **ë°ì´í„° ë¶„ì„**: Pandas, NumPy ë“± íŒ¨í‚¤ì§€  \n",
      "   - **ì¸ê³µì§€ëŠ¥(AI)**: TensorFlow, PyTorch ë“±  \n",
      "   - **ê²Œì„ ê°œë°œ**: Pygame, Godot ë“±  \n",
      "   - **ë°ì´í„° ê³¼í•™**: Scikit-learn, Matplotlib ë“±  \n",
      "3. **ì •í•´ì§„ ì–¸ì–´**: êµ¬ë¬¸ì— ëŒ€í•œ ê·œì¹™ì´ ëª…í™•í•˜ë©°, ì˜¤ë¥˜ë¥¼ ì‰½ê²Œ ì°¾ì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "4. **ê°œë°©ì„±**: ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ë¡œ, ì‚¬ìš©ìë“¤ì´ ì†ŒìŠ¤ ì½”ë“œë¥¼ ë³¼ ìˆ˜ ìˆìœ¼ë©°, ì»¤ë®¤ë‹ˆí‹°ê°€ ë¹ ë¥´ê²Œ ê¸°ëŠ¥ì„ ì¶”ê°€í•©ë‹ˆë‹¤.  \n",
      "\n",
      "### ì£¼ìš” ì´ì   \n",
      "- **ë‹¤ì¤‘ ì–¸ì–´ ì§€ì›**: Pythonì€ C, C++, Java, JavaScript ë“± ë‹¤ì–‘í•œ ì–¸ì–´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.  \n",
      "- **í¬ë¡œìŠ¤ í”Œë«í¼**: ìš´ì˜ ì²´ì œë‚˜ ì†Œí”„íŠ¸ì›¨ì–´ì— ê´€ê³„ì—†ì´ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.  \n",
      "- **ë‹¤ì–‘í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬**: ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ìˆ˜ëŠ” ìˆ˜ë°± ê°œë¡œ, ë‹¤ì–‘í•œ ëª©ì ì— ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.  \n",
      "\n",
      "### ì‚¬ìš© ì˜ˆ  \n",
      "```python\n",
      "# ë‹¨ìˆœí•œ ê³„ì‚°\n",
      "print(5 + 3)  # ì¶œë ¥: 8\n",
      "\n",
      "# ë°˜ë³µ\n",
      "for i in range(5):\n",
      "    print(i)  # 0, 1, 2, 3, 4\n",
      "\n",
      "# ì¡°ê±´ë¬¸\n",
      "if i % 2 == 0:\n",
      "    print(\"ì§ìˆ˜\")\n",
      "else:\n",
      "    print(\"í™€ìˆ˜\")\n",
      "```\n",
      "\n",
      "### ê²°ë¡   \n",
      "íŒŒì´ì¬ì€ ê°„ê²°í•˜ê³  ìœ ìš©í•œ ì–¸ì–´ë¡œ, í”„ë¡œê·¸ë˜ë¨¸ë“¤ì´ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì‰½ê²Œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ì»¤ë®¤ë‹ˆí‹°ì˜ ì§€ì›ì´ ê°•ì ì´ë©°, ì‹ ê¸°ìˆ ê³¼ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Ollamaë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ qwen2.5:1.5b ëª¨ë¸ ë¡œë“œ\n",
    "#llm = ChatOllama(model=\"qwen2.5:1.5b\")\n",
    "#qwen3:1.7b\n",
    "llm = ChatOllama(model=\"qwen3:1.7b\")\n",
    "\n",
    "# ë” ì •í™•í•œ ì‘ë‹µì„ ìœ„í•œ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "# ìµœì‹  LangChain ë°©ì‹: RunnableSequence í™œìš©\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# ì‹¤í–‰ ì˜ˆì‹œ\n",
    "question = \"íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dca27d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "First, I'll compare the whole number parts of both numbers. Both 9.9 and 9.11 have a whole number part of 9, so they are equal in that aspect.\n",
      "\n",
      "Next, I'll look at the decimal parts to determine which number is larger. The decimal part of 9.9 is .9, while that of 9.11 is .11.\n",
      "\n",
      "To make it easier to compare, I'll rewrite .9 as .90. Now, comparing .90 and .11, I can see that the tenths place is higher in .90 (9) than in .11 (1). Therefore, 9.90 is greater than 9.11.\n",
      "</think>\n",
      "\n",
      "To determine which number is larger between **9.9** and **9.11**, follow these steps:\n",
      "\n",
      "1. **Compare the Whole Number Parts:**\n",
      "   - Both numbers have the same whole number part: **9**.\n",
      "\n",
      "2. **Compare the Decimal Parts:**\n",
      "   - For 9.9, the decimal part is **0.9**.\n",
      "   - For 9.11, the decimal part is **0.11**.\n",
      "\n",
      "3. **Convert for Comparison:**\n",
      "   - Write 0.9 as **0.90** to match the number of decimal places in 0.11.\n",
      "   - Now, compare **0.90** and **0.11**:\n",
      "     - The tenths place (first digit after the decimal) is **9** for both numbers.\n",
      "     - Since **9 > 1**, it follows that **0.90 > 0.11**.\n",
      "\n",
      "4. **Conclusion:**\n",
      "   - Since the whole number parts are equal and the decimal part of **9.9** (0.90) is greater than that of **9.11** (0.11), we conclude that:\n",
      "\n",
      "\\[\n",
      "\\boxed{9.9 > 9.11}\n",
      "\\]"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "deepseek = ChatOllama(model=\"deepseek-r1:1.5b\", temperature=0.5)\n",
    "\n",
    "answer = []\n",
    "for chunk in deepseek.stream(\"which is bigger between 9.9 and 9.11?\"):\n",
    "    answer.append(chunk.content)\n",
    "    print(chunk.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e9e878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "First, I'll compare the whole number parts of both numbers. Both 9.9 and 9.11 have a whole number part of 9, so they are equal in that aspect.\n",
       "\n",
       "Next, I'll look at the decimal parts to determine which number is larger. The decimal part of 9.9 is .9, while that of 9.11 is .11.\n",
       "\n",
       "To make it easier to compare, I'll rewrite .9 as .90. Now, comparing .90 and .11, I can see that the tenths place is higher in .90 (9) than in .11 (1). Therefore, 9.90 is greater than 9.11.\n",
       "</think>\n",
       "\n",
       "To determine which number is larger between **9.9** and **9.11**, follow these steps:\n",
       "\n",
       "1. **Compare the Whole Number Parts:**\n",
       "   - Both numbers have the same whole number part: **9**.\n",
       "\n",
       "2. **Compare the Decimal Parts:**\n",
       "   - For 9.9, the decimal part is **0.9**.\n",
       "   - For 9.11, the decimal part is **0.11**.\n",
       "\n",
       "3. **Convert for Comparison:**\n",
       "   - Write 0.9 as **0.90** to match the number of decimal places in 0.11.\n",
       "   - Now, compare **0.90** and **0.11**:\n",
       "     - The tenths place (first digit after the decimal) is **9** for both numbers.\n",
       "     - Since **9 > 1**, it follows that **0.90 > 0.11**.\n",
       "\n",
       "4. **Conclusion:**\n",
       "   - Since the whole number parts are equal and the decimal part of **9.9** (0.90) is greater than that of **9.11** (0.11), we conclude that:\n",
       "\n",
       "\\[\n",
       "\\boxed{9.9 > 9.11}\n",
       "\\]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "answer_md=''.join([i for i in answer])\n",
    "display(Markdown(answer_md))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7e7dea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so the question is asking which is bigger between 9.9 and 9.11. Let me think about this step by step. \n",
      "\n",
      "First, I know that when comparing decimals, it's helpful to look at the digits from left to right. Both numbers are decimals with two digits after the decimal point. Let me write them out:\n",
      "\n",
      "9.9 is the same as 9.90, right? And 9.11 is 9.11. So, comparing them digit by digit.\n",
      "\n",
      "Starting with the whole number part: both are 9. So that's equal. Then, looking at the tenths place: the first number has 9 in the tenths place, and the second number has 1. Since 9 is greater than 1, even though the second number has more decimal places, the tenths place already shows that 9.9 is larger. \n",
      "\n",
      "Wait, but maybe I should check the decimal places more carefully. Let me break it down. \n",
      "\n",
      "9.9 is 9 + 0.9. 9.11 is 9 + 0.11. So, 0.9 is 0.90, and 0.11 is 0.11. Comparing 0.90 and 0.11, clearly 0.90 is larger. Therefore, 9.9 is larger than 9.11.\n",
      "\n",
      "But maybe I should consider if there's any trick here. For example, sometimes people might confuse the decimal places. Let me confirm. \n",
      "\n",
      "If I align them:\n",
      "\n",
      "9.90\n",
      "9.11\n",
      "\n",
      "Comparing the first decimal place: 9 vs 1. Since 9 is greater, the first number is larger. Even if the second number has more digits, the first digit in the tenths place is already larger. So, 9.9 is bigger than 9.11.\n",
      "\n",
      "Another way to think about it: 9.9 is 9.90, and 9.11 is 9.11. If I subtract 9.11 from 9.90, I get 0.79, which is positive, so 9.90 is larger. \n",
      "\n",
      "I don't think there's any other way to interpret this. The numbers are straightforward. The whole numbers are equal, but the tenths place in 9.9 is 9, which is more than 1 in the tenths place of 9.11. So, 9.9 is bigger.\n",
      "\n",
      "I guess that's it. The answer should be 9.9.\n",
      "</think>\n",
      "\n",
      "9.9ì™€ 9.11 ì¤‘ ë” í° ìˆ˜ëŠ” **9.9**ì…ë‹ˆë‹¤.  \n",
      "- ë‘ ìˆ˜ëŠ” ëª¨ë‘ 9ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.  \n",
      "- **ì‹­ë¶„ì˜ 1**ì˜ ìë¦¬ì—ì„œ 9.9ëŠ” 1ë³´ë‹¤ ë” í° ê°’ì´ë¯€ë¡œ, 9.9ëŠ” 9.11ë³´ë‹¤ ë” í° ìˆ˜ì…ë‹ˆë‹¤.  \n",
      "\n",
      "**ë‹µë³€:** 9.9  \n",
      "**ì´ìœ :** 9.9ëŠ” 9.11ë³´ë‹¤ 0.79 ë” í° ìˆ˜ì…ë‹ˆë‹¤."
     ]
    }
   ],
   "source": [
    "\n",
    "#model = ChatOllama(model=\"exaone3.5:2.4b\", temperature=0.5)\n",
    "#model = ChatOllama(model=\"qwen2.5:1.5b\", temperature=0.5)\n",
    "model = ChatOllama(model=\"qwen3:1.7b\", temperature=0.1)\n",
    "\n",
    "answer = []\n",
    "for chunk in model.stream(\"9.9ì™€ 9.11 ì¤‘ ë¬´ì—‡ì´ ë” í°ê°€ìš”?\"):\n",
    "    answer.append(chunk.content)\n",
    "    print(chunk.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c84aca05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, so the question is asking which is bigger between 9.9 and 9.11. Let me think about this step by step. \n",
       "\n",
       "First, I know that when comparing decimals, it's helpful to look at the digits from left to right. Both numbers are decimals with two digits after the decimal point. Let me write them out:\n",
       "\n",
       "9.9 is the same as 9.90, right? And 9.11 is 9.11. So, comparing them digit by digit.\n",
       "\n",
       "Starting with the whole number part: both are 9. So that's equal. Then, looking at the tenths place: the first number has 9 in the tenths place, and the second number has 1. Since 9 is greater than 1, even though the second number has more decimal places, the tenths place already shows that 9.9 is larger. \n",
       "\n",
       "Wait, but maybe I should check the decimal places more carefully. Let me break it down. \n",
       "\n",
       "9.9 is 9 + 0.9. 9.11 is 9 + 0.11. So, 0.9 is 0.90, and 0.11 is 0.11. Comparing 0.90 and 0.11, clearly 0.90 is larger. Therefore, 9.9 is larger than 9.11.\n",
       "\n",
       "But maybe I should consider if there's any trick here. For example, sometimes people might confuse the decimal places. Let me confirm. \n",
       "\n",
       "If I align them:\n",
       "\n",
       "9.90\n",
       "9.11\n",
       "\n",
       "Comparing the first decimal place: 9 vs 1. Since 9 is greater, the first number is larger. Even if the second number has more digits, the first digit in the tenths place is already larger. So, 9.9 is bigger than 9.11.\n",
       "\n",
       "Another way to think about it: 9.9 is 9.90, and 9.11 is 9.11. If I subtract 9.11 from 9.90, I get 0.79, which is positive, so 9.90 is larger. \n",
       "\n",
       "I don't think there's any other way to interpret this. The numbers are straightforward. The whole numbers are equal, but the tenths place in 9.9 is 9, which is more than 1 in the tenths place of 9.11. So, 9.9 is bigger.\n",
       "\n",
       "I guess that's it. The answer should be 9.9.\n",
       "</think>\n",
       "\n",
       "9.9ì™€ 9.11 ì¤‘ ë” í° ìˆ˜ëŠ” **9.9**ì…ë‹ˆë‹¤.  \n",
       "- ë‘ ìˆ˜ëŠ” ëª¨ë‘ 9ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.  \n",
       "- **ì‹­ë¶„ì˜ 1**ì˜ ìë¦¬ì—ì„œ 9.9ëŠ” 1ë³´ë‹¤ ë” í° ê°’ì´ë¯€ë¡œ, 9.9ëŠ” 9.11ë³´ë‹¤ ë” í° ìˆ˜ì…ë‹ˆë‹¤.  \n",
       "\n",
       "**ë‹µë³€:** 9.9  \n",
       "**ì´ìœ :** 9.9ëŠ” 9.11ë³´ë‹¤ 0.79 ë” í° ìˆ˜ì…ë‹ˆë‹¤."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "answer_md=''.join([i for i in answer])\n",
    "display(Markdown(answer_md))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07b0d8",
   "metadata": {},
   "source": [
    "### LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ DeepSeek ëª¨ë¸(ì¶”ë¡ )ê³¼ Qwen ëª¨ë¸(í•œê¸€ ì‘ë‹µ)ì„ ì—°ë™í•˜ê¸°\n",
    "* poetry add langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6f8eb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='deepseek-r1:1.5b' temperature=0.0 stop=['</think>']\n",
      "model='qwen3:1.7b' temperature=0.7\n",
      "input_variables=['question', 'thinking'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\n        ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  í¬ê´„ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\\n\\n        ë‹¹ì‹ ì˜ ì‘ì—…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\\n        - ì§ˆë¬¸ê³¼ ì œê³µëœ ì¶”ë¡ ì„ ì‹ ì¤‘í•˜ê²Œ ë¶„ì„í•˜ì„¸ìš”.\\n        - ì¶”ë¡ ì—ì„œ ì–»ì€ í†µì°°ë ¥ì„ í¬í•¨í•˜ì—¬ ì˜ êµ¬ì¡°í™”ëœ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.\\n        - ë‹µë³€ì´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ëŒ€ì‘í•˜ë„ë¡ í•˜ì„¸ìš”.\\n        - ì •ë³´ë¥¼ ëª…í™•í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì „ë‹¬í•˜ë˜, ì¶”ë¡  ê³¼ì •ì„ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.\\n\\n        ì§€ì¹¨:\\n        - ë‹µë³€ì„ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ê³ , í¥ë¯¸ë¡­ê²Œ ì „ë‹¬í•˜ì„¸ìš”.\\n        - ì¤‘ìš”í•œ í¬ì¸íŠ¸ë¥¼ ëª¨ë‘ ë‹¤ë£¨ë©´ì„œë„ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.\\n        - ì œê³µëœ ì¶”ë¡ ì„ ì‚¬ìš©í•œë‹¤ëŠ” ê²ƒì„ ì–¸ê¸‰í•˜ì§€ ë§ê³ , ê·¸ í†µì°°ë ¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨ì‹œí‚¤ì„¸ìš”.\\n        - ë„ì›€ì´ ë˜ê³  ì „ë¬¸ì ì¸ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”.\\n\\n        ëª©í‘œ: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ëŒ€ì‘í•˜ë©´ì„œ ì¶”ë¡  ê³¼ì •ì—ì„œ ì–»ì€ í†µì°°ë ¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•œ ì •ë³´ ì œê³µì…ë‹ˆë‹¤.\\n        '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question', 'thinking'], input_types={}, partial_variables={}, template='\\n        ì§ˆë¬¸: {question}\\n        ì¶”ë¡ : {thinking}\\n        '), additional_kwargs={})]\n",
      "<think>\n",
      "Okay, the user is asking which is larger between 9.9 and 9.11. Let me think through this step by step.\n",
      "\n",
      "First, I notice both numbers start with 9, so the whole numbers are equal. That means I need to look at the decimal parts to determine which is bigger. \n",
      "\n",
      "The first number is 9.9, and the second is 9.11. To compare them properly, I should align the decimal places. So, 9.9 becomes 9.90 when I add a zero to the end. Now, comparing 9.90 and 9.11:\n",
      "\n",
      "Looking at the tenths place, 9.90 has a 9, while 9.11 has a 1. Since 9 is greater than 1, the tenths place tells me that 9.90 is larger than 9.11.\n",
      "\n",
      "I should make sure I didn't miss any other digits. The units place is the same for both, so that doesn't affect the comparison. The decimal parts are the key here. Adding a zero to 9.9 makes it 9.90, which is clearly larger than 9.11.\n",
      "\n",
      "So, the conclusion is that 9.9 is larger than 9.11. I need to present this in a clear, conversational way without mentioning the reasoning process. Just state the comparison and the reason based on the decimal places.\n",
      "</think>\n",
      "\n",
      "9.9ì™€ 9.11 ì¤‘ 9.9ëŠ” ë” í¬ë‹¤. ë‘ ìˆ˜ëŠ” ì •ìˆ˜ ë¶€ë¶„(9)ì´ ê°™ì§€ë§Œ, ì†Œìˆ˜ ë¶€ë¶„ì„ ë¹„êµí•´ì•¼ í•©ë‹ˆë‹¤. 9.9ëŠ” 9.90ê³¼ ê°™ì´ 0ì„ ì¶”ê°€í•´ 9.90ìœ¼ë¡œ ë°”ê¾¸ë©´, 9.90ì™€ 9.11ì„ ë¹„êµí•  ë•Œ ì†Œìˆ˜ì  ì²« ë²ˆì§¸ ìë¦¬ì—ì„œ 9ê°€ 1ë³´ë‹¤ í¬ë¯€ë¡œ 9.90ì´ ë” í¬ë‹¤. ë”°ë¼ì„œ 9.9ëŠ” 9.11ë³´ë‹¤ ë” ì»¤ìš”.\n",
      "{'question': '9.9ì™€ 9.11 ì¤‘ ë¬´ì—‡ì´ ë” í°ê°€ìš”?', 'thinking': \"<think>\\nFirst, I need to compare the two numbers: 9.9 and 9.11.\\n\\nBoth numbers have the same whole number part, which is 9.\\n\\nTo make a fair comparison, I'll align their decimal places by writing 9.9 as 9.90.\\n\\nNow, comparing each digit from left to right:\\n\\n- The units place for both numbers is 9.\\n- In the tenths place, 9 has a 9 and 9.11 has a 1.\\n  \\nSince 9 is greater than 1 in the tenths place, 9.90 is larger than 9.11.\\n\\nTherefore, 9.9 is greater than 9.11.\\n\", 'answer': \"<think>\\nOkay, the user is asking which is larger between 9.9 and 9.11. Let me think through this step by step.\\n\\nFirst, I notice both numbers start with 9, so the whole numbers are equal. That means I need to look at the decimal parts to determine which is bigger. \\n\\nThe first number is 9.9, and the second is 9.11. To compare them properly, I should align the decimal places. So, 9.9 becomes 9.90 when I add a zero to the end. Now, comparing 9.90 and 9.11:\\n\\nLooking at the tenths place, 9.90 has a 9, while 9.11 has a 1. Since 9 is greater than 1, the tenths place tells me that 9.90 is larger than 9.11.\\n\\nI should make sure I didn't miss any other digits. The units place is the same for both, so that doesn't affect the comparison. The decimal parts are the key here. Adding a zero to 9.9 makes it 9.90, which is clearly larger than 9.11.\\n\\nSo, the conclusion is that 9.9 is larger than 9.11. I need to present this in a clear, conversational way without mentioning the reasoning process. Just state the comparison and the reason based on the decimal places.\\n</think>\\n\\n9.9ì™€ 9.11 ì¤‘ 9.9ëŠ” ë” í¬ë‹¤. ë‘ ìˆ˜ëŠ” ì •ìˆ˜ ë¶€ë¶„(9)ì´ ê°™ì§€ë§Œ, ì†Œìˆ˜ ë¶€ë¶„ì„ ë¹„êµí•´ì•¼ í•©ë‹ˆë‹¤. 9.9ëŠ” 9.90ê³¼ ê°™ì´ 0ì„ ì¶”ê°€í•´ 9.90ìœ¼ë¡œ ë°”ê¾¸ë©´, 9.90ì™€ 9.11ì„ ë¹„êµí•  ë•Œ ì†Œìˆ˜ì  ì²« ë²ˆì§¸ ìë¦¬ì—ì„œ 9ê°€ 1ë³´ë‹¤ í¬ë¯€ë¡œ 9.90ì´ ë” í¬ë‹¤. ë”°ë¼ì„œ 9.9ëŠ” 9.11ë³´ë‹¤ ë” ì»¤ìš”.\"}\n",
      "==> ìƒì„±ëœ ë‹µë³€: \n",
      "\n",
      "<think>\n",
      "Okay, the user is asking which is larger between 9.9 and 9.11. Let me think through this step by step.\n",
      "\n",
      "First, I notice both numbers start with 9, so the whole numbers are equal. That means I need to look at the decimal parts to determine which is bigger. \n",
      "\n",
      "The first number is 9.9, and the second is 9.11. To compare them properly, I should align the decimal places. So, 9.9 becomes 9.90 when I add a zero to the end. Now, comparing 9.90 and 9.11:\n",
      "\n",
      "Looking at the tenths place, 9.90 has a 9, while 9.11 has a 1. Since 9 is greater than 1, the tenths place tells me that 9.90 is larger than 9.11.\n",
      "\n",
      "I should make sure I didn't miss any other digits. The units place is the same for both, so that doesn't affect the comparison. The decimal parts are the key here. Adding a zero to 9.9 makes it 9.90, which is clearly larger than 9.11.\n",
      "\n",
      "So, the conclusion is that 9.9 is larger than 9.11. I need to present this in a clear, conversational way without mentioning the reasoning process. Just state the comparison and the reason based on the decimal places.\n",
      "</think>\n",
      "\n",
      "9.9ì™€ 9.11 ì¤‘ 9.9ëŠ” ë” í¬ë‹¤. ë‘ ìˆ˜ëŠ” ì •ìˆ˜ ë¶€ë¶„(9)ì´ ê°™ì§€ë§Œ, ì†Œìˆ˜ ë¶€ë¶„ì„ ë¹„êµí•´ì•¼ í•©ë‹ˆë‹¤. 9.9ëŠ” 9.90ê³¼ ê°™ì´ 0ì„ ì¶”ê°€í•´ 9.90ìœ¼ë¡œ ë°”ê¾¸ë©´, 9.90ì™€ 9.11ì„ ë¹„êµí•  ë•Œ ì†Œìˆ˜ì  ì²« ë²ˆì§¸ ìë¦¬ì—ì„œ 9ê°€ 1ë³´ë‹¤ í¬ë¯€ë¡œ 9.90ì´ ë” í¬ë‹¤. ë”°ë¼ì„œ 9.9ëŠ” 9.11ë³´ë‹¤ ë” ì»¤ìš”.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "reasoning_model = ChatOllama(model=\"deepseek-r1:1.5b\", temperature=0, stop=[\"</think>\"])\n",
    "print(reasoning_model)\n",
    "\n",
    "#generation_model = ChatOllama(model=\"qwen2.5:1.5b\", temperature=0.7)\n",
    "generation_model = ChatOllama(model=\"qwen3:1.7b\", temperature=0.7)\n",
    "print(generation_model)\n",
    "\n",
    "answer_prompt = ChatPromptTemplate([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "        ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  í¬ê´„ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "        ë‹¹ì‹ ì˜ ì‘ì—…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "        - ì§ˆë¬¸ê³¼ ì œê³µëœ ì¶”ë¡ ì„ ì‹ ì¤‘í•˜ê²Œ ë¶„ì„í•˜ì„¸ìš”.\n",
    "        - ì¶”ë¡ ì—ì„œ ì–»ì€ í†µì°°ë ¥ì„ í¬í•¨í•˜ì—¬ ì˜ êµ¬ì¡°í™”ëœ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "        - ë‹µë³€ì´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ëŒ€ì‘í•˜ë„ë¡ í•˜ì„¸ìš”.\n",
    "        - ì •ë³´ë¥¼ ëª…í™•í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì „ë‹¬í•˜ë˜, ì¶”ë¡  ê³¼ì •ì„ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "\n",
    "        ì§€ì¹¨:\n",
    "        - ë‹µë³€ì„ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ê³ , í¥ë¯¸ë¡­ê²Œ ì „ë‹¬í•˜ì„¸ìš”.\n",
    "        - ì¤‘ìš”í•œ í¬ì¸íŠ¸ë¥¼ ëª¨ë‘ ë‹¤ë£¨ë©´ì„œë„ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "        - ì œê³µëœ ì¶”ë¡ ì„ ì‚¬ìš©í•œë‹¤ëŠ” ê²ƒì„ ì–¸ê¸‰í•˜ì§€ ë§ê³ , ê·¸ í†µì°°ë ¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨ì‹œí‚¤ì„¸ìš”.\n",
    "        - ë„ì›€ì´ ë˜ê³  ì „ë¬¸ì ì¸ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”.\n",
    "\n",
    "        ëª©í‘œ: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ëŒ€ì‘í•˜ë©´ì„œ ì¶”ë¡  ê³¼ì •ì—ì„œ ì–»ì€ í†µì°°ë ¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•œ ì •ë³´ ì œê³µì…ë‹ˆë‹¤.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"\"\"\n",
    "        ì§ˆë¬¸: {question}\n",
    "        ì¶”ë¡ : {thinking}\n",
    "        \"\"\"\n",
    "    )\n",
    "])\n",
    "print(answer_prompt)\n",
    "\n",
    "#LangGraphì—ì„œ State ì‚¬ìš©ìì •ì˜ í´ë˜ìŠ¤ëŠ” ë…¸ë“œ ê°„ì˜ ì •ë³´ë¥¼ ì „ë‹¬í•˜ëŠ” í‹€ì…ë‹ˆë‹¤. \n",
    "#ë…¸ë“œ ê°„ì— ê³„ì† ì „ë‹¬í•˜ê³  ì‹¶ê±°ë‚˜, ê·¸ë˜í”„ ë‚´ì—ì„œ ìœ ì§€í•´ì•¼ í•  ì •ë³´ë¥¼ ë¯¸ë¦¬ ì •ì˜í™ë‹ˆë‹¤. \n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    thinking: str\n",
    "    answer: str\n",
    "\n",
    "#DeepSeekë¥¼ í†µí•´ì„œ ì¶”ë¡  ë¶€ë¶„ê¹Œì§€ë§Œ ìƒì„±í•©ë‹ˆë‹¤. \n",
    "def think(state: State):\n",
    "    question = state[\"question\"]\n",
    "    response = reasoning_model.invoke(question)\n",
    "    #print(response.content)\n",
    "    return {\"thinking\": response.content}\n",
    "\n",
    "#Qwenë¥¼ í†µí•´ì„œ ê²°ê³¼ ì¶œë ¥ ë¶€ë¶„ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "def generate(state: State):\n",
    "    messages = answer_prompt.invoke({\"question\": state[\"question\"], \"thinking\": state[\"thinking\"]})\n",
    "    response = generation_model.invoke(messages)\n",
    "    print(response.content)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph_builder = StateGraph(State).add_sequence([think, generate]) # thinkë‘ generateëŠ” ìœ„ì— í•¨ìˆ˜ ì´ë¦„ì„.\n",
    "graph_builder.add_edge(START, \"think\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# ì…ë ¥ ë°ì´í„°\n",
    "inputs = {\"question\": \"9.9ì™€ 9.11 ì¤‘ ë¬´ì—‡ì´ ë” í°ê°€ìš”?\"}\n",
    "\n",
    "# invoke()ë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ í˜¸ì¶œ\n",
    "result = graph.invoke(inputs)\n",
    "print(result)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"==> ìƒì„±ëœ ë‹µë³€: \\n\")\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76d80bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)        \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "add76d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "First, I need to compare the two numbers: 9.9 and 9.11.\n",
      "\n",
      "To make an accurate comparison, it's helpful to express both numbers with the same number of decimal places. This means converting 9.9 into 9.90.\n",
      "\n",
      "Now that both numbers have two decimal places, I can directly compare them digit by digit from left to right.\n",
      "\n",
      "Starting with the units place: Both numbers have a 9 in the units place, so they are equal there.\n",
      "\n",
      "Next, looking at the tenths place: The first number has a 9, and the second number has a 1. Since 9 is greater than 1, this means that 9.90 is larger than 9.11.\n",
      "\n",
      "Therefore, 9.9 is greater than 9.11.\n",
      "<think>\n",
      "Okay, let's see. The user is asking which is bigger between 9.9 and 9.11. Hmm. I need to figure out the answer. \n",
      "\n",
      "First, I remember that when comparing decimals, you start from the leftmost digit. Both numbers are straightforward. 9.9 is the same as 9.90 when you add a zero at the end, right? So, 9.90 versus 9.11. \n",
      "\n",
      "Wait, the tenths place: 9.9 has a 9 in the tenths, and 9.11 has a 1. So, 9 is bigger than 1, so even though the units are the same, the tenths place makes 9.90 larger. \n",
      "\n",
      "So, even though 9.9 is written without a decimal, it's actually 9.90. Therefore, 9.90 is bigger than 9.11. So the answer is 9.9 is larger. \n",
      "\n",
      "I need to make sure there's no confusion. Sometimes people might think that 9.9 is shorter, but in decimal terms, adding a zero doesn't change the value. So yes, 9.9 is bigger. \n",
      "\n",
      "I should explain this step by step, starting with converting both numbers to have the same decimal places, then comparing each digit. That way, the user understands the process.\n",
      "</think>\n",
      "\n",
      "9.9ì™€ 9.11 ì¤‘ 9.9ëŠ” ë” í° ìˆ˜ì…ë‹ˆë‹¤.  \n",
      "ì´ ë‘ ìˆ˜ëŠ” ì†Œìˆ˜ì  ìë¦¬ ìˆ˜ë¥¼ ë§ì¶°ì„œ ë¹„êµí•˜ë©´ 9.90ê³¼ 9.11ì´ ë©ë‹ˆë‹¤.  \n",
      "ì†Œìˆ˜ì  ì²« ë²ˆì§¸ ìë¦¬(ì‹­ë¶„ì˜ 1)ì—ì„œ 9ê°€ 1ë³´ë‹¤ í°ê°’ì„ ê°€ì§ˆ ìˆ˜ ìˆì–´, 9.90ì´ 9.11ë³´ë‹¤ ë” í° ìˆ˜ì…ë‹ˆë‹¤.  \n",
      "ë”°ë¼ì„œ 9.9ì€ 9.11ë³´ë‹¤ ë” í° ìˆ˜ì…ë‹ˆë‹¤.<think>\n",
      "Okay, let's see. The user is asking which is bigger between 9.9 and 9.11. Hmm. I need to figure out the answer. \n",
      "\n",
      "First, I remember that when comparing decimals, you start from the leftmost digit. Both numbers are straightforward. 9.9 is the same as 9.90 when you add a zero at the end, right? So, 9.90 versus 9.11. \n",
      "\n",
      "Wait, the tenths place: 9.9 has a 9 in the tenths, and 9.11 has a 1. So, 9 is bigger than 1, so even though the units are the same, the tenths place makes 9.90 larger. \n",
      "\n",
      "So, even though 9.9 is written without a decimal, it's actually 9.90. Therefore, 9.90 is bigger than 9.11. So the answer is 9.9 is larger. \n",
      "\n",
      "I need to make sure there's no confusion. Sometimes people might think that 9.9 is shorter, but in decimal terms, adding a zero doesn't change the value. So yes, 9.9 is bigger. \n",
      "\n",
      "I should explain this step by step, starting with converting both numbers to have the same decimal places, then comparing each digit. That way, the user understands the process.\n",
      "</think>\n",
      "\n",
      "9.9ì™€ 9.11 ì¤‘ 9.9ëŠ” ë” í° ìˆ˜ì…ë‹ˆë‹¤.  \n",
      "ì´ ë‘ ìˆ˜ëŠ” ì†Œìˆ˜ì  ìë¦¬ ìˆ˜ë¥¼ ë§ì¶°ì„œ ë¹„êµí•˜ë©´ 9.90ê³¼ 9.11ì´ ë©ë‹ˆë‹¤.  \n",
      "ì†Œìˆ˜ì  ì²« ë²ˆì§¸ ìë¦¬(ì‹­ë¶„ì˜ 1)ì—ì„œ 9ê°€ 1ë³´ë‹¤ í°ê°’ì„ ê°€ì§ˆ ìˆ˜ ìˆì–´, 9.90ì´ 9.11ë³´ë‹¤ ë” í° ìˆ˜ì…ë‹ˆë‹¤.  \n",
      "ë”°ë¼ì„œ 9.9ì€ 9.11ë³´ë‹¤ ë” í° ìˆ˜ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"9.9ì™€ 9.11 ì¤‘ ë¬´ì—‡ì´ ë” í°ê°€ìš”?\"}\n",
    "\n",
    "async for event in graph.astream_events(inputs, version=\"v2\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        print(event['data']['chunk'].content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eda48c",
   "metadata": {},
   "source": [
    "### 2ê°œì˜ ëª¨ë¸ì„ ì—°ë™í•œ ì½”ë“œë¥¼ Gradioë¥¼ ì‚¬ìš©í•˜ì—¬ UIë¡œ ì‹¤í–‰í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de4bd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-basic-kGdHTiMZ-py3.12\\Lib\\site-packages\\gradio\\chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] ì…ë ¥ ì§ˆë¬¸: íŒŒì´ì¬ì´ë€?\n",
      "[DEBUG] ì§ˆë¬¸ íƒ€ì…: <class 'str'>\n",
      "[DEBUG] ì¶”ë¡  ê²°ê³¼ íƒ€ì…: <class 'str'>\n",
      "[DEBUG] ì¶”ë¡  ê²°ê³¼ ê¸¸ì´: 9\n",
      "[DEBUG] ì¶”ë¡  ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°: <think>\n",
      "\n",
      "...\n",
      "[DEBUG] generate í•¨ìˆ˜ - ì§ˆë¬¸: íŒŒì´ì¬ì´ë€?\n",
      "[DEBUG] generate í•¨ìˆ˜ - ì¶”ë¡  ê¸¸ì´: 9\n",
      "[DEBUG] generate í•¨ìˆ˜ - ì¶”ë¡  ë¯¸ë¦¬ë³´ê¸°: <think>\n",
      "\n",
      "...\n",
      "[DEBUG] í”„ë¡¬í”„íŠ¸ ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ\n",
      "[DEBUG] ìµœì¢… ì‘ë‹µ íƒ€ì…: <class 'str'>\n",
      "[DEBUG] ìµœì¢… ì‘ë‹µ ê¸¸ì´: 1088\n",
      "[DEBUG] ìµœì¢… ì‘ë‹µ ë‚´ìš©: <think>\n",
      "Okay, let's see. The user asked, \"íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€?\" which means \"What is Python?\" and provided the inference process. The task is to create a natural, conversational Korean answer without explicitly mentioning the inference process.\n",
      "\n",
      "First, I need to explain what Python is. It's a programming language, right? I should mention it's used for various purposes like web development, data analysis, automation, etc. Also, note that it's known for being easy to learn and read, which makes it popular among beginners. Maybe add that it's open-source and has a vast ecosystem. Keep it simple and friendly, like a chat response. Avoid technical jargon but make sure the key points are covered. Check for clarity and flow, making sure it's not too long but still informative. Alright, let's put it all together in a natural, engaging way.\n",
      "</think>\n",
      "\n",
      "íŒŒì´ì¬ì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ì¤‘ í•˜ë‚˜ë¡œ, ê°„ê²°í•˜ê³  ì½ê¸° ì‰½ê²Œ ì„¤ê³„ëœ ì–¸ì–´ë¡œ, ì›¹ ê°œë°œ, ë°ì´í„° ë¶„ì„, ìë™í™”, ì¸ê³µì§€ëŠ¥ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ë„ë¦¬ í™œìš©ë©ë‹ˆë‹¤. íŠ¹íˆ, ì´ˆë³´ìë„ ì‰½ê²Œ ë°°ì›Œì„œ \"Python is easy to learn\"ë¼ëŠ” í‰ê°€ë¥¼ ë°›ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì–¸ì–´ëŠ” ëŒ€ê·œëª¨ ì»¤ë®¤ë‹ˆí‹°ì™€ í•¨ê»˜ ë‹¤ì–‘í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬(ì˜ˆ: NumPy, Pandas, Django ë“±)ë¥¼ ì œê³µí•´ ì‹¤ìš©ì ì¸ ì†”ë£¨ì…˜ì„ ë§Œë“¤ ìˆ˜ ìˆì–´ ì¸ê¸° ìˆëŠ” ì–¸ì–´ë¡œ ìë¦¬ ì¡ì•˜ìŠµë‹ˆë‹¤. ğŸ\n",
      "[DEBUG] ì…ë ¥ ì§ˆë¬¸: íŒŒì´ì¬ì´ë€?\n",
      "[DEBUG] ì§ˆë¬¸ íƒ€ì…: <class 'str'>\n",
      "[DEBUG] ì¶”ë¡  ê²°ê³¼ íƒ€ì…: <class 'str'>\n",
      "[DEBUG] ì¶”ë¡  ê²°ê³¼ ê¸¸ì´: 9\n",
      "[DEBUG] ì¶”ë¡  ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°: <think>\n",
      "\n",
      "...\n",
      "[DEBUG] generate í•¨ìˆ˜ - ì§ˆë¬¸: íŒŒì´ì¬ì´ë€?\n",
      "[DEBUG] generate í•¨ìˆ˜ - ì¶”ë¡  ê¸¸ì´: 9\n",
      "[DEBUG] generate í•¨ìˆ˜ - ì¶”ë¡  ë¯¸ë¦¬ë³´ê¸°: <think>\n",
      "\n",
      "...\n",
      "[DEBUG] í”„ë¡¬í”„íŠ¸ ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ\n",
      "[DEBUG] ìµœì¢… ì‘ë‹µ íƒ€ì…: <class 'str'>\n",
      "[DEBUG] ìµœì¢… ì‘ë‹µ ê¸¸ì´: 1537\n",
      "[DEBUG] ìµœì¢… ì‘ë‹µ ë‚´ìš©: <think>\n",
      "Okay, let's tackle this question. The user is asking, \"What is Python?\" and the provided inference is about Python being a programming language. I need to create a natural, conversational response in Korean without explicitly mentioning the inference.\n",
      "\n",
      "First, I should recall the key points about Python. It's a high-level, general-purpose language, known for its readability. It's widely used in web development, data analysis, machine learning, and more. Also, it's interpreted, which means it's easier to debug. Features like dynamic typing and a vast standard library are important. Maybe mention the community and ease of learning as benefits.\n",
      "\n",
      "I need to structure the answer to directly address the question. Start with a simple definition, then list the main features. Use examples like web development with Django or data analysis with pandas. Highlight why it's popularâ€”readability, ease of use, extensive libraries. Avoid technical jargon but keep it accurate. Make sure it's friendly and engaging, like a conversation. Check for clarity and flow, ensuring each point connects logically. Avoid any markdown and keep the tone professional yet approachable.\n",
      "</think>\n",
      "\n",
      "íŒŒì´ì¬ì€ ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ìš´ ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆëŠ” ê³ ì „ì ì¸ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. ì´ ì–¸ì–´ëŠ” ë™ì  íƒ€ì… íŠ¹ì„±ê³¼ ì§ê´€ì ì¸ ë¬¸ë²•ìœ¼ë¡œ, ë°ì´í„° ë¶„ì„, ì›¹ ê°œë°œ, ë¨¸ì‹ ëŸ¬ë‹ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ë„ë¦¬ í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. íŒŒì´ì¬ì€ ê°„ê²°í•œ ì½”ë“œë¡œ ë³µì¡í•œ ì‘ì—…ë„ ì‰½ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆìœ¼ë©°, í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í’ë¶€í•œ ê¸°ëŠ¥ê³¼ ì»¤ë®¤ë‹ˆí‹°ì˜ ë¹ ë¥¸ ë°œì „ìœ¼ë¡œ ì¸í•´ ê°œë°œìë“¤ì—ê²Œ í° ì‚¬ë‘ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ Djangoë¡œ ê°œë°œí•˜ê±°ë‚˜, ë°ì´í„° ë¶„ì„ì„ pandasë¡œ ì²˜ë¦¬í•  ë•Œ íŒŒì´ì¬ì˜ íš¨ìœ¨ì„±ê³¼ ëª…í™•ì„±ì€ ë§¤ìš° ìœ ë¦¬í•©ë‹ˆë‹¤. ìš”ì•½í•˜ë©´, íŒŒì´ì¬ì€ ì½”ë“œë¥¼ ì‰½ê²Œ ì‘ì„±í•˜ê³  ìœ ì§€í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë„êµ¬ë¡œ, í”„ë¡œê·¸ë˜ë° ì„¸ê³„ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "[DEBUG] ì…ë ¥ ì§ˆë¬¸: langchainì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "[DEBUG] ì§ˆë¬¸ íƒ€ì…: <class 'str'>\n",
      "[DEBUG] ì¶”ë¡  ê²°ê³¼ íƒ€ì…: <class 'str'>\n",
      "[DEBUG] ì¶”ë¡  ê²°ê³¼ ê¸¸ì´: 3764\n",
      "[DEBUG] ì¶”ë¡  ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°: <think>\n",
      "Okay, so I'm trying to understand what LangChain is. From the previous explanation, it seems like it's a tool that combines language models with some kind of search engine or something similar...\n",
      "[DEBUG] generate í•¨ìˆ˜ - ì§ˆë¬¸: langchainì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "[DEBUG] generate í•¨ìˆ˜ - ì¶”ë¡  ê¸¸ì´: 3764\n",
      "[DEBUG] generate í•¨ìˆ˜ - ì¶”ë¡  ë¯¸ë¦¬ë³´ê¸°: <think>\n",
      "Okay, so I'm trying to understand what LangChain is. From the previous explanation, it seems like it's a tool that combines language models with some kind of search engine or something similar...\n",
      "[DEBUG] í”„ë¡¬í”„íŠ¸ ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ\n",
      "[DEBUG] ìµœì¢… ì‘ë‹µ íƒ€ì…: <class 'str'>\n",
      "[DEBUG] ìµœì¢… ì‘ë‹µ ê¸¸ì´: 515\n",
      "[DEBUG] ìµœì¢… ì‘ë‹µ ë‚´ìš©: <think>\n",
      "</think>\n",
      "\n",
      "LangChainëŠ” ì–¸ì–´ ëª¨ë¸ê³¼ ì—°ê²°ëœ ìˆ˜ìš©ê¸° ì‹œìŠ¤í…œìœ¼ë¡œ, ë‹¤ì–‘í•œ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ëŠ” ë‹¨ìˆœí•œ ì–¸ì–´ ëª¨ë¸ê³¼ êµ¬ë³„ë˜ë©°, ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  ì²˜ë¦¬í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, \"ì•„í”„ë¦¬ì¹´ì˜ ê¸°í›„ ë³€í™” ìƒí™©ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\"ë¼ê³  ë¬»ë©´, LangChainëŠ” ëª¨ë¸ì˜ ì§€ì‹ ë²”ìœ„ ë‚´ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•„ë‚´ì–´ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì‚¬ìš©ìëŠ” ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤(ì˜ˆ: ë¸Œë¼ìš°ì €, ë°ì´í„°ë² ì´ìŠ¤ ë“±)ì™€ ì—°ë™í•˜ì—¬ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. LangChainëŠ” ìœ ì—°ì„±ê³¼ í™•ì¥ì„±ì„ ê°•ì¡°í•˜ë©°, ê°œë°œìë“¤ì´ ê¸°ì¡´ì˜ ì‹œìŠ¤í…œê³¼ ì‰½ê²Œ ê²°í•©í•˜ì—¬ ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì¶”ê°€í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ íŠ¹ì •ly ì •í•´ì§„ ì£¼ì œë‚˜ ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìœ¼ë©°, ëª¨ë¸ì˜ ì§€ì‹ ë²”ìœ„ ë‚´ì—ì„œë§Œ ì²˜ë¦¬ë©ë‹ˆë‹¤. ì´ëŠ” ì‚¬ìš©ìì—ê²Œ í¸ë¦¬í•œ ì •ë³´ ì ‘ê·¼ì„ ì œê³µí•˜ì§€ë§Œ, ì™„ì „í•œ ì „ë¬¸ ì§€ì‹ì„ ë³´ìœ í•˜ì§€ ì•ŠëŠ” ê²½ìš° ë‹µë³€ì˜ ì •í™•ì„±ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import sys\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# UTF-8 ì¸ì½”ë”© ê°•ì œ ì„¤ì • (Jupyter ë…¸íŠ¸ë¶ í˜¸í™˜)\n",
    "os.environ['PYTHONIOENCODING'] = 'utf-8'\n",
    "os.environ['LANG'] = 'ko_KR.UTF-8'\n",
    "os.environ['LC_ALL'] = 'ko_KR.UTF-8'\n",
    "\n",
    "# Jupyter í™˜ê²½ì—ì„œëŠ” reconfigure ëŒ€ì‹  í™˜ê²½ë³€ìˆ˜ë¡œ ì²˜ë¦¬\n",
    "try:\n",
    "    if hasattr(sys.stdout, 'reconfigure') and sys.stdout.encoding != 'utf-8':\n",
    "        sys.stdout.reconfigure(encoding='utf-8')\n",
    "except (AttributeError, OSError):\n",
    "    # Jupyter ë…¸íŠ¸ë¶ì´ë‚˜ ë‹¤ë¥¸ í™˜ê²½ì—ì„œëŠ” íŒ¨ìŠ¤\n",
    "    pass\n",
    "\n",
    "# ëª¨ë¸ ì„¤ì •: ë‘ ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ ê³¼ ë‹µë³€ ìƒì„±ì„ ìˆ˜í–‰\n",
    "# - reasoning_model: ì¶”ë¡ ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë¸ (ì˜¨ë„ ë‚®ìŒ, ì •í™•í•œ ë¶„ì„ìš©)\n",
    "# - generation_model: ë‹µë³€ ìƒì„±ì„ ë‹´ë‹¹í•˜ëŠ” ëª¨ë¸ (ì˜¨ë„ ë†’ìŒ, ì°½ì˜ì  ì‘ë‹µìš©)\n",
    "reasoning_model = ChatOllama(\n",
    "    model=\"deepseek-r1:1.5b\", \n",
    "    temperature=0, \n",
    "    stop=[\"</think>\"]\n",
    ")\n",
    "\n",
    "generation_model = ChatOllama(\n",
    "    #model=\"qwen2.5:1.5b\", \n",
    "    model=\"qwen3:1.7b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# ìƒíƒœ(State) ì •ì˜: ê·¸ë˜í”„ì—ì„œ ìƒíƒœë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•œ ë°ì´í„° êµ¬ì¡°\n",
    "class State(TypedDict):\n",
    "    question: str   # ì‚¬ìš©ìì˜ ì§ˆë¬¸\n",
    "    thinking: str   # ì¶”ë¡  ê²°ê³¼\n",
    "    answer: str     # ìµœì¢… ë‹µë³€\n",
    "\n",
    "# ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "answer_prompt = ChatPromptTemplate([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. \n",
    "        ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "        \n",
    "        ë‹¹ì‹ ì˜ ì‘ì—…:\n",
    "        - ì§ˆë¬¸ê³¼ ì œê³µëœ ì¶”ë¡ ì„ ì‹ ì¤‘í•˜ê²Œ ë¶„ì„í•˜ì„¸ìš”.\n",
    "        - ì¶”ë¡ ì—ì„œ ì–»ì€ í†µì°°ë ¥ì„ í¬í•¨í•˜ì—¬ ì˜ êµ¬ì¡°í™”ëœ í•œêµ­ì–´ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "        - ë‹µë³€ì´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ëŒ€ì‘í•˜ë„ë¡ í•˜ì„¸ìš”.\n",
    "        - ì •ë³´ë¥¼ ëª…í™•í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì „ë‹¬í•˜ë˜, ì¶”ë¡  ê³¼ì •ì„ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "        \n",
    "        ì§€ì¹¨:\n",
    "        - ë‹µë³€ì„ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ê³ , í¥ë¯¸ë¡­ê²Œ ì „ë‹¬í•˜ì„¸ìš”.\n",
    "        - ì¤‘ìš”í•œ í¬ì¸íŠ¸ë¥¼ ëª¨ë‘ ë‹¤ë£¨ë©´ì„œë„ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "        - ì œê³µëœ ì¶”ë¡ ì„ ì‚¬ìš©í•œë‹¤ëŠ” ê²ƒì„ ì–¸ê¸‰í•˜ì§€ ë§ê³ , ê·¸ í†µì°°ë ¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨ì‹œí‚¤ì„¸ìš”.\n",
    "        - ë„ì›€ì´ ë˜ê³  ì „ë¬¸ì ì¸ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”.\n",
    "        \n",
    "        ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.\"\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"\"\"ì§ˆë¬¸: {question}\n",
    "        \n",
    "        ì¶”ë¡  ê³¼ì •: {thinking}\n",
    "        \n",
    "        ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:\"\"\"\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "def ensure_utf8_string(text):\n",
    "    \"\"\"ë¬¸ìì—´ì´ UTF-8ë¡œ ì œëŒ€ë¡œ ì¸ì½”ë”©ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  ë³€í™˜\"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    if isinstance(text, bytes):\n",
    "        try:\n",
    "            return text.decode('utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            return text.decode('utf-8', errors='ignore')\n",
    "    \n",
    "    # ë¬¸ìì—´ì´ì§€ë§Œ ì¸ì½”ë”© ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆëŠ” ê²½ìš° ì²˜ë¦¬\n",
    "    if isinstance(text, str):\n",
    "        try:\n",
    "            # ë¬¸ìì—´ì„ UTF-8ë¡œ ì¸ì½”ë”©í–ˆë‹¤ê°€ ë‹¤ì‹œ ë””ì½”ë”©í•˜ì—¬ ì •ë¦¬\n",
    "            return text.encode('utf-8').decode('utf-8')\n",
    "        except (UnicodeEncodeError, UnicodeDecodeError):\n",
    "            return text\n",
    "    \n",
    "    return str(text)\n",
    "\n",
    "# DeepSeekë¥¼ í†µí•´ì„œ ì¶”ë¡  ë¶€ë¶„ê¹Œì§€ë§Œ ìƒì„±\n",
    "def think(state: State):\n",
    "    question = state[\"question\"]\n",
    "    print(f\"[DEBUG] ì…ë ¥ ì§ˆë¬¸: {question}\")\n",
    "    print(f\"[DEBUG] ì§ˆë¬¸ íƒ€ì…: {type(question)}\")\n",
    "    \n",
    "    response = reasoning_model.invoke(question)\n",
    "    thinking_content = ensure_utf8_string(response.content)\n",
    "    \n",
    "    print(f\"[DEBUG] ì¶”ë¡  ê²°ê³¼ íƒ€ì…: {type(response.content)}\")\n",
    "    print(f\"[DEBUG] ì¶”ë¡  ê²°ê³¼ ê¸¸ì´: {len(thinking_content)}\")\n",
    "    print(f\"[DEBUG] ì¶”ë¡  ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°: {thinking_content[:200]}...\")\n",
    "    \n",
    "    return {\"thinking\": thinking_content}\n",
    "\n",
    "# qwen2.5ë¥¼ í†µí•´ì„œ ê²°ê³¼ ì¶œë ¥ ë¶€ë¶„ì„ ìƒì„±\n",
    "def generate(state: State):\n",
    "    # question = ensure_utf8_string(state[\"question\"])\n",
    "    # thinking = ensure_utf8_string(state[\"thinking\"])\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    thinking = state[\"thinking\"]\n",
    "    \n",
    "    print(f\"[DEBUG] generate í•¨ìˆ˜ - ì§ˆë¬¸: {question}\")\n",
    "    print(f\"[DEBUG] generate í•¨ìˆ˜ - ì¶”ë¡  ê¸¸ì´: {len(thinking)}\")\n",
    "    print(f\"[DEBUG] generate í•¨ìˆ˜ - ì¶”ë¡  ë¯¸ë¦¬ë³´ê¸°: {thinking[:200]}...\")\n",
    "    \n",
    "    messages = answer_prompt.invoke({\n",
    "        \"question\": question, \n",
    "        \"thinking\": thinking\n",
    "    })\n",
    "    \n",
    "    print(f\"[DEBUG] í”„ë¡¬í”„íŠ¸ ë©”ì‹œì§€ ìƒì„± ì™„ë£Œ\")\n",
    "    \n",
    "    response = generation_model.invoke(messages)\n",
    "    answer_content = ensure_utf8_string(response.content)\n",
    "    \n",
    "    print(f\"[DEBUG] ìµœì¢… ì‘ë‹µ íƒ€ì…: {type(response.content)}\")\n",
    "    print(f\"[DEBUG] ìµœì¢… ì‘ë‹µ ê¸¸ì´: {len(answer_content)}\")\n",
    "    print(f\"[DEBUG] ìµœì¢… ì‘ë‹µ ë‚´ìš©: {answer_content}\")\n",
    "    \n",
    "    return {\"answer\": answer_content}\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒì„± í•¨ìˆ˜: ìƒíƒœ(State) ê°„ì˜ íë¦„ì„ ì •ì˜\n",
    "def create_graph():\n",
    "    graph_builder = StateGraph(State).add_sequence([think, generate])\n",
    "    graph_builder.add_edge(START, \"think\")\n",
    "    return graph_builder.compile()\n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„± ë° ì‹¤í–‰\n",
    "def chatbot_interface(message, history):\n",
    "    graph = create_graph()\n",
    "    inputs = {\"question\": message}\n",
    "    result = graph.invoke(inputs)\n",
    "    return result[\"answer\"]\n",
    "\n",
    "iface = gr.ChatInterface(fn=chatbot_interface, title=\"AI ì±—ë´‡\", description=\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ AIê°€ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì„¤ì •\n",
    "# def launch_gradio():\n",
    "#     iface = gr.Interface(fn=chatbot_interface, inputs=\"text\", outputs=\"text\", title=\"AI ì±—ë´‡\", description=\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ AIê°€ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.\")\n",
    "#     iface.launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()\n",
    "    #launch_gradio()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
