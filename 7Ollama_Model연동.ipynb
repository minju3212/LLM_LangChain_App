{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "161c0025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama is running\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"http://127.0.0.1:11434\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f448c5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "('<think>\\n'\n",
      " '\\n'\n",
      " '</think>\\n'\n",
      " '\\n'\n",
      " 'LangChain is a high-level Python library for integrating language models '\n",
      " 'into applications, enabling developers to focus on their core tasks without '\n",
      " 'being overwhelmed by the low-level details of how to interact with them. It '\n",
      " 'provides abstractions for interacting with various model types (like '\n",
      " 'prompting, data fetching, and more), handling common interfaces (APIs and '\n",
      " 'clients), and managing complexity around API key management, logging, and '\n",
      " 'logging APIs. LangChain makes it easier to create custom applications that '\n",
      " 'can use any kind of language model without needing to understand the '\n",
      " 'intricacies of how they work under the hood.\\n'\n",
      " '\\n'\n",
      " 'Key features of LangChain include:\\n'\n",
      " '\\n'\n",
      " '1. **Model Management**: A simple way to switch between different model '\n",
      " 'types (like GPT-3, BERT, etc.) and use them within your application.\\n'\n",
      " '2. **Data Handling**: Simplifies interacting with external data sources '\n",
      " 'using an API client.\\n'\n",
      " '3. **Error Management**: Provides a unified API for error logging and '\n",
      " 'handling, making it easier to diagnose issues during development.\\n'\n",
      " '4. **Documentation and Tutorials**: LangChain includes documentation and '\n",
      " 'sample code for quick start guidance.\\n'\n",
      " '\\n'\n",
      " 'By abstracting away the complexities of working with language models, '\n",
      " 'LangChain allows developers to focus on building applications that leverage '\n",
      " 'these powerful tools. It is particularly useful in industries like chatbots, '\n",
      " 'customer service, content generation, and more where custom applications may '\n",
      " 'need to interact with external data sources or multiple model types.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pprint import pprint\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 llama3.2 모델 로드\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"What is LangChain?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(type(response))\n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90636bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking \"파이썬은 무엇인가요?\" which translates to \"What is Python?\" in English. I need to provide a detailed and accurate answer.\n",
      "\n",
      "First, I should start by defining Python as a programming language. Mention its creation, creator, and the year it was released. Then, highlight its key features like simplicity, readability, and versatility. It's important to note that Python is widely used in various fields such as web development, data analysis, artificial intelligence, and more.\n",
      "\n",
      "I should also include some basic information about its syntax, like how it uses indentation instead of braces, and the significance of the \"P\" in Python (for \"Python\" as in \"Programming Language\"). Maybe mention the community and resources available, like the official website and documentation.\n",
      "\n",
      "Additionally, it's good to touch on some popular libraries and frameworks that are part of Python, such as Django for web development, NumPy and pandas for data analysis, and TensorFlow or PyTorch for machine learning. Highlighting its popularity and the fact that it's open-source can add value.\n",
      "\n",
      "I need to make sure the answer is clear and not too technical, but still informative. Avoid jargon unless necessary, and explain terms like \"interpreted language\" and \"cross-platform\" if they're relevant. Also, mention that Python is used in both small scripts and large-scale applications.\n",
      "\n",
      "Check for any recent updates or changes in Python's features, but since the user is asking a general question, sticking to the basics is better. Maybe end with a positive note about its usefulness and the community support.\n",
      "</think>\n",
      "\n",
      "파이썬은 프로그래밍 언어로, 1991년에 간단하고 읽기 쉬운 문법을 특징으로 한 Python 라이브러리가 개발되었습니다. 이 언어는 간결한 문법과 높은 생산성으로 인해 다양한 분야에서 널리 사용됩니다.  \n",
      "\n",
      "### 주요 특징  \n",
      "1. **간결한 문법**: `if` 문에 `else`를 붙이기 위한 `if` 문법과 `for` 문에 `in`을 붙이기 위한 `for` 문법 등이 있지만, 들여쓰기로 문장을 구분하는 방식으로, 코드의 읽기 쉬움을 강조합니다.  \n",
      "2. **다양한 활용 분야**:  \n",
      "   - **웹 개발**: Django, Flask 등 라이브러리 활용  \n",
      "   - **데이터 분석**: Pandas, NumPy 등 패키지  \n",
      "   - **인공지능(AI)**: TensorFlow, PyTorch 등  \n",
      "   - **게임 개발**: Pygame, Godot 등  \n",
      "   - **데이터 과학**: Scikit-learn, Matplotlib 등  \n",
      "3. **정해진 언어**: 구문에 대한 규칙이 명확하며, 오류를 쉽게 찾아볼 수 있습니다.  \n",
      "4. **개방성**: 오픈소스 프로젝트로, 사용자들이 소스 코드를 볼 수 있으며, 커뮤니티가 빠르게 기능을 추가합니다.  \n",
      "\n",
      "### 주요 이점  \n",
      "- **다중 언어 지원**: Python은 C, C++, Java, JavaScript 등 다양한 언어를 지원합니다.  \n",
      "- **크로스 플랫폼**: 운영 체제나 소프트웨어에 관계없이 사용 가능합니다.  \n",
      "- **다양한 라이브러리**: 라이브러리의 수는 수백 개로, 다양한 목적에 사용 가능합니다.  \n",
      "\n",
      "### 사용 예  \n",
      "```python\n",
      "# 단순한 계산\n",
      "print(5 + 3)  # 출력: 8\n",
      "\n",
      "# 반복\n",
      "for i in range(5):\n",
      "    print(i)  # 0, 1, 2, 3, 4\n",
      "\n",
      "# 조건문\n",
      "if i % 2 == 0:\n",
      "    print(\"짝수\")\n",
      "else:\n",
      "    print(\"홀수\")\n",
      "```\n",
      "\n",
      "### 결론  \n",
      "파이썬은 간결하고 유용한 언어로, 프로그래머들이 다양한 분야에서 쉽게 활용할 수 있습니다. 주요 라이브러리와 커뮤니티의 지원이 강점이며, 신기술과 빠르게 발전하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 qwen2.5:1.5b 모델 로드\n",
    "#llm = ChatOllama(model=\"qwen2.5:1.5b\")\n",
    "#qwen3:1.7b\n",
    "llm = ChatOllama(model=\"qwen3:1.7b\")\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"파이썬은 무엇인가요?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dca27d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "First, I'll compare the whole number parts of both numbers. Both 9.9 and 9.11 have a whole number part of 9, so they are equal in that aspect.\n",
      "\n",
      "Next, I'll look at the decimal parts to determine which number is larger. The decimal part of 9.9 is .9, while that of 9.11 is .11.\n",
      "\n",
      "To make it easier to compare, I'll rewrite .9 as .90. Now, comparing .90 and .11, I can see that the tenths place is higher in .90 (9) than in .11 (1). Therefore, 9.90 is greater than 9.11.\n",
      "</think>\n",
      "\n",
      "To determine which number is larger between **9.9** and **9.11**, follow these steps:\n",
      "\n",
      "1. **Compare the Whole Number Parts:**\n",
      "   - Both numbers have the same whole number part: **9**.\n",
      "\n",
      "2. **Compare the Decimal Parts:**\n",
      "   - For 9.9, the decimal part is **0.9**.\n",
      "   - For 9.11, the decimal part is **0.11**.\n",
      "\n",
      "3. **Convert for Comparison:**\n",
      "   - Write 0.9 as **0.90** to match the number of decimal places in 0.11.\n",
      "   - Now, compare **0.90** and **0.11**:\n",
      "     - The tenths place (first digit after the decimal) is **9** for both numbers.\n",
      "     - Since **9 > 1**, it follows that **0.90 > 0.11**.\n",
      "\n",
      "4. **Conclusion:**\n",
      "   - Since the whole number parts are equal and the decimal part of **9.9** (0.90) is greater than that of **9.11** (0.11), we conclude that:\n",
      "\n",
      "\\[\n",
      "\\boxed{9.9 > 9.11}\n",
      "\\]"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "deepseek = ChatOllama(model=\"deepseek-r1:1.5b\", temperature=0.5)\n",
    "\n",
    "answer = []\n",
    "for chunk in deepseek.stream(\"which is bigger between 9.9 and 9.11?\"):\n",
    "    answer.append(chunk.content)\n",
    "    print(chunk.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e9e878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "First, I'll compare the whole number parts of both numbers. Both 9.9 and 9.11 have a whole number part of 9, so they are equal in that aspect.\n",
       "\n",
       "Next, I'll look at the decimal parts to determine which number is larger. The decimal part of 9.9 is .9, while that of 9.11 is .11.\n",
       "\n",
       "To make it easier to compare, I'll rewrite .9 as .90. Now, comparing .90 and .11, I can see that the tenths place is higher in .90 (9) than in .11 (1). Therefore, 9.90 is greater than 9.11.\n",
       "</think>\n",
       "\n",
       "To determine which number is larger between **9.9** and **9.11**, follow these steps:\n",
       "\n",
       "1. **Compare the Whole Number Parts:**\n",
       "   - Both numbers have the same whole number part: **9**.\n",
       "\n",
       "2. **Compare the Decimal Parts:**\n",
       "   - For 9.9, the decimal part is **0.9**.\n",
       "   - For 9.11, the decimal part is **0.11**.\n",
       "\n",
       "3. **Convert for Comparison:**\n",
       "   - Write 0.9 as **0.90** to match the number of decimal places in 0.11.\n",
       "   - Now, compare **0.90** and **0.11**:\n",
       "     - The tenths place (first digit after the decimal) is **9** for both numbers.\n",
       "     - Since **9 > 1**, it follows that **0.90 > 0.11**.\n",
       "\n",
       "4. **Conclusion:**\n",
       "   - Since the whole number parts are equal and the decimal part of **9.9** (0.90) is greater than that of **9.11** (0.11), we conclude that:\n",
       "\n",
       "\\[\n",
       "\\boxed{9.9 > 9.11}\n",
       "\\]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "answer_md=''.join([i for i in answer])\n",
    "display(Markdown(answer_md))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7e7dea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so the question is asking which is bigger between 9.9 and 9.11. Let me think about this step by step. \n",
      "\n",
      "First, I know that when comparing decimals, it's helpful to look at the digits from left to right. Both numbers are decimals with two digits after the decimal point. Let me write them out:\n",
      "\n",
      "9.9 is the same as 9.90, right? And 9.11 is 9.11. So, comparing them digit by digit.\n",
      "\n",
      "Starting with the whole number part: both are 9. So that's equal. Then, looking at the tenths place: the first number has 9 in the tenths place, and the second number has 1. Since 9 is greater than 1, even though the second number has more decimal places, the tenths place already shows that 9.9 is larger. \n",
      "\n",
      "Wait, but maybe I should check the decimal places more carefully. Let me break it down. \n",
      "\n",
      "9.9 is 9 + 0.9. 9.11 is 9 + 0.11. So, 0.9 is 0.90, and 0.11 is 0.11. Comparing 0.90 and 0.11, clearly 0.90 is larger. Therefore, 9.9 is larger than 9.11.\n",
      "\n",
      "But maybe I should consider if there's any trick here. For example, sometimes people might confuse the decimal places. Let me confirm. \n",
      "\n",
      "If I align them:\n",
      "\n",
      "9.90\n",
      "9.11\n",
      "\n",
      "Comparing the first decimal place: 9 vs 1. Since 9 is greater, the first number is larger. Even if the second number has more digits, the first digit in the tenths place is already larger. So, 9.9 is bigger than 9.11.\n",
      "\n",
      "Another way to think about it: 9.9 is 9.90, and 9.11 is 9.11. If I subtract 9.11 from 9.90, I get 0.79, which is positive, so 9.90 is larger. \n",
      "\n",
      "I don't think there's any other way to interpret this. The numbers are straightforward. The whole numbers are equal, but the tenths place in 9.9 is 9, which is more than 1 in the tenths place of 9.11. So, 9.9 is bigger.\n",
      "\n",
      "I guess that's it. The answer should be 9.9.\n",
      "</think>\n",
      "\n",
      "9.9와 9.11 중 더 큰 수는 **9.9**입니다.  \n",
      "- 두 수는 모두 9를 기준으로 시작합니다.  \n",
      "- **십분의 1**의 자리에서 9.9는 1보다 더 큰 값이므로, 9.9는 9.11보다 더 큰 수입니다.  \n",
      "\n",
      "**답변:** 9.9  \n",
      "**이유:** 9.9는 9.11보다 0.79 더 큰 수입니다."
     ]
    }
   ],
   "source": [
    "\n",
    "#model = ChatOllama(model=\"exaone3.5:2.4b\", temperature=0.5)\n",
    "#model = ChatOllama(model=\"qwen2.5:1.5b\", temperature=0.5)\n",
    "model = ChatOllama(model=\"qwen3:1.7b\", temperature=0.1)\n",
    "\n",
    "answer = []\n",
    "for chunk in model.stream(\"9.9와 9.11 중 무엇이 더 큰가요?\"):\n",
    "    answer.append(chunk.content)\n",
    "    print(chunk.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c84aca05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, so the question is asking which is bigger between 9.9 and 9.11. Let me think about this step by step. \n",
       "\n",
       "First, I know that when comparing decimals, it's helpful to look at the digits from left to right. Both numbers are decimals with two digits after the decimal point. Let me write them out:\n",
       "\n",
       "9.9 is the same as 9.90, right? And 9.11 is 9.11. So, comparing them digit by digit.\n",
       "\n",
       "Starting with the whole number part: both are 9. So that's equal. Then, looking at the tenths place: the first number has 9 in the tenths place, and the second number has 1. Since 9 is greater than 1, even though the second number has more decimal places, the tenths place already shows that 9.9 is larger. \n",
       "\n",
       "Wait, but maybe I should check the decimal places more carefully. Let me break it down. \n",
       "\n",
       "9.9 is 9 + 0.9. 9.11 is 9 + 0.11. So, 0.9 is 0.90, and 0.11 is 0.11. Comparing 0.90 and 0.11, clearly 0.90 is larger. Therefore, 9.9 is larger than 9.11.\n",
       "\n",
       "But maybe I should consider if there's any trick here. For example, sometimes people might confuse the decimal places. Let me confirm. \n",
       "\n",
       "If I align them:\n",
       "\n",
       "9.90\n",
       "9.11\n",
       "\n",
       "Comparing the first decimal place: 9 vs 1. Since 9 is greater, the first number is larger. Even if the second number has more digits, the first digit in the tenths place is already larger. So, 9.9 is bigger than 9.11.\n",
       "\n",
       "Another way to think about it: 9.9 is 9.90, and 9.11 is 9.11. If I subtract 9.11 from 9.90, I get 0.79, which is positive, so 9.90 is larger. \n",
       "\n",
       "I don't think there's any other way to interpret this. The numbers are straightforward. The whole numbers are equal, but the tenths place in 9.9 is 9, which is more than 1 in the tenths place of 9.11. So, 9.9 is bigger.\n",
       "\n",
       "I guess that's it. The answer should be 9.9.\n",
       "</think>\n",
       "\n",
       "9.9와 9.11 중 더 큰 수는 **9.9**입니다.  \n",
       "- 두 수는 모두 9를 기준으로 시작합니다.  \n",
       "- **십분의 1**의 자리에서 9.9는 1보다 더 큰 값이므로, 9.9는 9.11보다 더 큰 수입니다.  \n",
       "\n",
       "**답변:** 9.9  \n",
       "**이유:** 9.9는 9.11보다 0.79 더 큰 수입니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "answer_md=''.join([i for i in answer])\n",
    "display(Markdown(answer_md))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07b0d8",
   "metadata": {},
   "source": [
    "### LangGraph를 사용하여 DeepSeek 모델(추론)과 Qwen 모델(한글 응답)을 연동하기\n",
    "* poetry add langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6f8eb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='deepseek-r1:1.5b' temperature=0.0 stop=['</think>']\n",
      "model='qwen3:1.7b' temperature=0.7\n",
      "input_variables=['question', 'thinking'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\n        당신은 사용자의 질문에 대해 명확하고 포괄적인 답변을 제공하는 AI 어시스턴트입니다.\\n\\n        당신의 작업은 다음과 같습니다:\\n        - 질문과 제공된 추론을 신중하게 분석하세요.\\n        - 추론에서 얻은 통찰력을 포함하여 잘 구조화된 답변을 생성하세요.\\n        - 답변이 사용자의 질문에 직접적으로 대응하도록 하세요.\\n        - 정보를 명확하고 자연스럽게 전달하되, 추론 과정을 명시적으로 언급하지 마세요.\\n\\n        지침:\\n        - 답변을 대화 형식으로 작성하고, 흥미롭게 전달하세요.\\n        - 중요한 포인트를 모두 다루면서도 명확하고 간결하게 작성하세요.\\n        - 제공된 추론을 사용한다는 것을 언급하지 말고, 그 통찰력을 자연스럽게 포함시키세요.\\n        - 도움이 되고 전문적인 톤을 유지하세요.\\n\\n        목표: 사용자의 질문에 직접적으로 대응하면서 추론 과정에서 얻은 통찰력을 자연스럽게 포함한 정보 제공입니다.\\n        '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question', 'thinking'], input_types={}, partial_variables={}, template='\\n        질문: {question}\\n        추론: {thinking}\\n        '), additional_kwargs={})]\n",
      "<think>\n",
      "Okay, the user is asking which is larger between 9.9 and 9.11. Let me think through this step by step.\n",
      "\n",
      "First, I notice both numbers start with 9, so the whole numbers are equal. That means I need to look at the decimal parts to determine which is bigger. \n",
      "\n",
      "The first number is 9.9, and the second is 9.11. To compare them properly, I should align the decimal places. So, 9.9 becomes 9.90 when I add a zero to the end. Now, comparing 9.90 and 9.11:\n",
      "\n",
      "Looking at the tenths place, 9.90 has a 9, while 9.11 has a 1. Since 9 is greater than 1, the tenths place tells me that 9.90 is larger than 9.11.\n",
      "\n",
      "I should make sure I didn't miss any other digits. The units place is the same for both, so that doesn't affect the comparison. The decimal parts are the key here. Adding a zero to 9.9 makes it 9.90, which is clearly larger than 9.11.\n",
      "\n",
      "So, the conclusion is that 9.9 is larger than 9.11. I need to present this in a clear, conversational way without mentioning the reasoning process. Just state the comparison and the reason based on the decimal places.\n",
      "</think>\n",
      "\n",
      "9.9와 9.11 중 9.9는 더 크다. 두 수는 정수 부분(9)이 같지만, 소수 부분을 비교해야 합니다. 9.9는 9.90과 같이 0을 추가해 9.90으로 바꾸면, 9.90와 9.11을 비교할 때 소수점 첫 번째 자리에서 9가 1보다 크므로 9.90이 더 크다. 따라서 9.9는 9.11보다 더 커요.\n",
      "{'question': '9.9와 9.11 중 무엇이 더 큰가요?', 'thinking': \"<think>\\nFirst, I need to compare the two numbers: 9.9 and 9.11.\\n\\nBoth numbers have the same whole number part, which is 9.\\n\\nTo make a fair comparison, I'll align their decimal places by writing 9.9 as 9.90.\\n\\nNow, comparing each digit from left to right:\\n\\n- The units place for both numbers is 9.\\n- In the tenths place, 9 has a 9 and 9.11 has a 1.\\n  \\nSince 9 is greater than 1 in the tenths place, 9.90 is larger than 9.11.\\n\\nTherefore, 9.9 is greater than 9.11.\\n\", 'answer': \"<think>\\nOkay, the user is asking which is larger between 9.9 and 9.11. Let me think through this step by step.\\n\\nFirst, I notice both numbers start with 9, so the whole numbers are equal. That means I need to look at the decimal parts to determine which is bigger. \\n\\nThe first number is 9.9, and the second is 9.11. To compare them properly, I should align the decimal places. So, 9.9 becomes 9.90 when I add a zero to the end. Now, comparing 9.90 and 9.11:\\n\\nLooking at the tenths place, 9.90 has a 9, while 9.11 has a 1. Since 9 is greater than 1, the tenths place tells me that 9.90 is larger than 9.11.\\n\\nI should make sure I didn't miss any other digits. The units place is the same for both, so that doesn't affect the comparison. The decimal parts are the key here. Adding a zero to 9.9 makes it 9.90, which is clearly larger than 9.11.\\n\\nSo, the conclusion is that 9.9 is larger than 9.11. I need to present this in a clear, conversational way without mentioning the reasoning process. Just state the comparison and the reason based on the decimal places.\\n</think>\\n\\n9.9와 9.11 중 9.9는 더 크다. 두 수는 정수 부분(9)이 같지만, 소수 부분을 비교해야 합니다. 9.9는 9.90과 같이 0을 추가해 9.90으로 바꾸면, 9.90와 9.11을 비교할 때 소수점 첫 번째 자리에서 9가 1보다 크므로 9.90이 더 크다. 따라서 9.9는 9.11보다 더 커요.\"}\n",
      "==> 생성된 답변: \n",
      "\n",
      "<think>\n",
      "Okay, the user is asking which is larger between 9.9 and 9.11. Let me think through this step by step.\n",
      "\n",
      "First, I notice both numbers start with 9, so the whole numbers are equal. That means I need to look at the decimal parts to determine which is bigger. \n",
      "\n",
      "The first number is 9.9, and the second is 9.11. To compare them properly, I should align the decimal places. So, 9.9 becomes 9.90 when I add a zero to the end. Now, comparing 9.90 and 9.11:\n",
      "\n",
      "Looking at the tenths place, 9.90 has a 9, while 9.11 has a 1. Since 9 is greater than 1, the tenths place tells me that 9.90 is larger than 9.11.\n",
      "\n",
      "I should make sure I didn't miss any other digits. The units place is the same for both, so that doesn't affect the comparison. The decimal parts are the key here. Adding a zero to 9.9 makes it 9.90, which is clearly larger than 9.11.\n",
      "\n",
      "So, the conclusion is that 9.9 is larger than 9.11. I need to present this in a clear, conversational way without mentioning the reasoning process. Just state the comparison and the reason based on the decimal places.\n",
      "</think>\n",
      "\n",
      "9.9와 9.11 중 9.9는 더 크다. 두 수는 정수 부분(9)이 같지만, 소수 부분을 비교해야 합니다. 9.9는 9.90과 같이 0을 추가해 9.90으로 바꾸면, 9.90와 9.11을 비교할 때 소수점 첫 번째 자리에서 9가 1보다 크므로 9.90이 더 크다. 따라서 9.9는 9.11보다 더 커요.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "reasoning_model = ChatOllama(model=\"deepseek-r1:1.5b\", temperature=0, stop=[\"</think>\"])\n",
    "print(reasoning_model)\n",
    "\n",
    "#generation_model = ChatOllama(model=\"qwen2.5:1.5b\", temperature=0.7)\n",
    "generation_model = ChatOllama(model=\"qwen3:1.7b\", temperature=0.7)\n",
    "print(generation_model)\n",
    "\n",
    "answer_prompt = ChatPromptTemplate([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "        당신은 사용자의 질문에 대해 명확하고 포괄적인 답변을 제공하는 AI 어시스턴트입니다.\n",
    "\n",
    "        당신의 작업은 다음과 같습니다:\n",
    "        - 질문과 제공된 추론을 신중하게 분석하세요.\n",
    "        - 추론에서 얻은 통찰력을 포함하여 잘 구조화된 답변을 생성하세요.\n",
    "        - 답변이 사용자의 질문에 직접적으로 대응하도록 하세요.\n",
    "        - 정보를 명확하고 자연스럽게 전달하되, 추론 과정을 명시적으로 언급하지 마세요.\n",
    "\n",
    "        지침:\n",
    "        - 답변을 대화 형식으로 작성하고, 흥미롭게 전달하세요.\n",
    "        - 중요한 포인트를 모두 다루면서도 명확하고 간결하게 작성하세요.\n",
    "        - 제공된 추론을 사용한다는 것을 언급하지 말고, 그 통찰력을 자연스럽게 포함시키세요.\n",
    "        - 도움이 되고 전문적인 톤을 유지하세요.\n",
    "\n",
    "        목표: 사용자의 질문에 직접적으로 대응하면서 추론 과정에서 얻은 통찰력을 자연스럽게 포함한 정보 제공입니다.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\n",
    "        \"\"\"\n",
    "        질문: {question}\n",
    "        추론: {thinking}\n",
    "        \"\"\"\n",
    "    )\n",
    "])\n",
    "print(answer_prompt)\n",
    "\n",
    "#LangGraph에서 State 사용자정의 클래스는 노드 간의 정보를 전달하는 틀입니다. \n",
    "#노드 간에 계속 전달하고 싶거나, 그래프 내에서 유지해야 할 정보를 미리 정의힙니다. \n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    thinking: str\n",
    "    answer: str\n",
    "\n",
    "#DeepSeek를 통해서 추론 부분까지만 생성합니다. \n",
    "def think(state: State):\n",
    "    question = state[\"question\"]\n",
    "    response = reasoning_model.invoke(question)\n",
    "    #print(response.content)\n",
    "    return {\"thinking\": response.content}\n",
    "\n",
    "#Qwen를 통해서 결과 출력 부분을 생성합니다.\n",
    "def generate(state: State):\n",
    "    messages = answer_prompt.invoke({\"question\": state[\"question\"], \"thinking\": state[\"thinking\"]})\n",
    "    response = generation_model.invoke(messages)\n",
    "    print(response.content)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph_builder = StateGraph(State).add_sequence([think, generate]) # think랑 generate는 위에 함수 이름임.\n",
    "graph_builder.add_edge(START, \"think\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# 입력 데이터\n",
    "inputs = {\"question\": \"9.9와 9.11 중 무엇이 더 큰가요?\"}\n",
    "\n",
    "# invoke()를 사용하여 그래프 호출\n",
    "result = graph.invoke(inputs)\n",
    "print(result)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"==> 생성된 답변: \\n\")\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76d80bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)        \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add76d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
